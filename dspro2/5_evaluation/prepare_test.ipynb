{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import concurrent\n",
    "import torch\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from image_data_handler_test import TestImageDataHandler\n",
    "from geo_model_tester import GeoModelTester\n",
    "from wandb_downloader import WandbDownloader\n",
    "from custom_image_dataset_test import CustomImageDatasetTest\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import resolve_env_variable, load_image_file_raw, get_image_files\n",
    "\n",
    "sys.path.insert(0, './4_modeling')\n",
    "from region_handler import RegionHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data path:  C:\\Users\\yutar\\Documents\\HSLU\\Paper_data\\yfcc4k\n"
     ]
    }
   ],
   "source": [
    "region_handler = RegionHandler()\n",
    "\n",
    "test_data_path = \"C:\\\\Users\\\\yutar\\\\Documents\\\\HSLU\\\\Paper_data\\\\yfcc4k\"\n",
    "print(\"Test data path: \", test_data_path)\n",
    "image_path = os.path.join(test_data_path, \"image_processed\")\n",
    "json_path = os.path.join(test_data_path, \"jsons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files:  4536\n",
      "Number of json files:  4536\n"
     ]
    }
   ],
   "source": [
    "# get all image files\n",
    "image_files = [os.path.join(image_path, f) for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]\n",
    "print(\"Number of image files: \", len(image_files))\n",
    "json_files = [os.path.join(json_path, f) for f in os.listdir(json_path) if os.path.isfile(os.path.join(json_path, f))]\n",
    "print(\"Number of json files: \", len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all image files have a corresponding json file and vice versa by comparing the file names without the extension\n",
    "image_file_names = [os.path.splitext(os.path.basename(f))[0] for f in image_files]\n",
    "json_file_names = [os.path.splitext(os.path.basename(f))[0] for f in json_files]\n",
    "image_file_names = set(image_file_names)\n",
    "json_file_names = set(json_file_names)\n",
    "\n",
    "# check if all image files have a corresponding json file\n",
    "missing_json_files = image_file_names - json_file_names\n",
    "if len(missing_json_files) > 0:\n",
    "    print(\"Missing json files: \", missing_json_files)\n",
    "\n",
    "# check if all json files have a corresponding image file\n",
    "missing_image_files = json_file_names - image_file_names\n",
    "if len(missing_image_files) > 0:\n",
    "    print(\"Missing image files: \", missing_image_files)\n",
    "\n",
    "# remove image files without a corresponding json file\n",
    "image_files = [f for f in image_files if os.path.splitext(os.path.basename(f))[0] not in missing_json_files]\n",
    "\n",
    "# remove json files without a corresponding image file\n",
    "json_files = [f for f in json_files if os.path.splitext(os.path.basename(f))[0] not in missing_image_files]\n",
    "\n",
    "# create a list of tuples with the image and the data inside corresponding json file \"coordinates\":, \"country_name\", \"country_code\", \"regions\", \"is_in_region\" as keys\n",
    "data = []\n",
    "for image_file in image_files:\n",
    "    image_file_name = os.path.splitext(os.path.basename(image_file))[0]\n",
    "    json_file = [f for f in json_files if os.path.splitext(os.path.basename(f))[0] == image_file_name]\n",
    "    if len(json_file) == 1:\n",
    "        json_file = json_file[0]\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "            data.append((image_file, json_data))\n",
    "\n",
    "# print first 5 entries\n",
    "for i in range(5):\n",
    "    print(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "running_device = \"colab_L4\"\n",
    "image_size = [80, 130]\n",
    "data_augmentation = \"base_augmentation\" # or \"base_augmentation\", \"full_augmentation_v2\"\n",
    "predict_coordinates=False\n",
    "predict_regions=True\n",
    "\n",
    "if running_device == \"colab_L4\":\n",
    "    # Run unmapped images with low image resolution\n",
    "    USE_MAPPED = False\n",
    "\n",
    "elif running_device == \"colab_A100\":\n",
    "    # Run mapped images with high image resolution\n",
    "    image_size = [180, 320]\n",
    "    NUMBER_OF_FILES = 79000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type = \"regions\" if predict_regions else (\"coordinates\" if predict_coordinates else \"countries\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "preprocessing_config = { 'data_augmentation': data_augmentation, 'height': image_size[0], 'width': image_size[1], 'train_ratio': train_ratio, 'val_ratio': val_ratio, 'test_ratio': test_ratio }\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "          transforms.Resize((image_size[0], image_size[1])),\n",
    "        ])\n",
    "augmented_transform = None\n",
    "final_transform = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "if data_augmentation == \"full_augmentation_v2\":\n",
    "    base_transform = transforms.Compose([])\n",
    "    augmented_transform = transforms.Compose([\n",
    "        # Disabled because black bars really hurt the performance at this size (only for v2)\n",
    "        # transforms.RandomPerspective(distortion_scale=0.75, p=0.5),  # Randomly apply perspective transformation\n",
    "        transforms.RandomResizedCrop((image_size[0], image_size[1]), scale=(0.75, 1.0)),  # Randomly crop the image and resize it to the original size\n",
    "        transforms.RandomRotation(10),          # Randomly rotate the image by up to 10 degrees, sadly also causes black borders\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),  # Randomly change brightness (lower limit to simulate night, upper limit for bright daylight)\n",
    "            contrast=(0.5, 1.5),    # Randomly change contrast\n",
    "            saturation=(0.5, 1.5),  # Randomly change saturation\n",
    "            hue=(-0.1, 0.1)         # Randomly change hue\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"predicting-coordinates\" if predict_coordinates else (\"predicting-region\" if predict_regions else \"predicting-country\")\n",
    "sweep_metric_name = \"Validation Distance (km)\" if predict_coordinates or predict_regions else \"Validation Accuracy Top 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\yutar\\.netrc\n",
      "wandb: Currently logged in as: yutarosigrist (nlp-yuuta). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching runs found.\n"
     ]
    }
   ],
   "source": [
    "wandb_downloader = WandbDownloader(entity=\"nlp_ls\", project=f\"dspro2-{project_name}\", data_augmentation=data_augmentation, input_image_size=image_size)\n",
    "\n",
    "file_names_to_download = [\".pth\", \".json\"]\n",
    "\n",
    "run_data = wandb_downloader.get_and_collect_best_runs(sweep_metric_name, file_names_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

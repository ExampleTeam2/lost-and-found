{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkillusions\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking run 8xpu0otw\n",
      "Successfully updated summary of run 8xpu0otw with test_data_run_id: w1098m89\n",
      "Checking run hd3f2sg1\n",
      "Successfully updated summary of run hd3f2sg1 with test_data_run_id: w1098m89\n",
      "Checking run xvurwdi8\n",
      "Successfully updated summary of run xvurwdi8 with test_data_run_id: w1098m89\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "# Log in to WandB\n",
    "wandb.login()\n",
    "\n",
    "# Replace with your entity, project, and run ID\n",
    "entity = \"nlp_ls\"\n",
    "projects = [\"dspro2-predicting-country\", \"dspro2-predicting-region\", \"dspro2-predicting-coordinates\"]\n",
    "run_ids = [\"*:10\"]  # or [...]\n",
    "\n",
    "# Value to add to the summary\n",
    "summary_key = None  # \"test_data_run_id\"\n",
    "summary_value = None  # \"blablabla\"\n",
    "\n",
    "# Push best Validation Accuracy * and Validation Distance and Validation Loss as Logs\n",
    "push_best = True\n",
    "# Whether to recalculate the best values, or only push them if they are not already in the summary (recommended to set to False)\n",
    "force_recalculate = False\n",
    "\n",
    "# Access the run\n",
    "api = wandb.Api()\n",
    "all_non_special_used_run_ids = []\n",
    "for project in projects:\n",
    "    all_project_runs = [run.id for run in api.runs(f\"{entity}/{project}\")]\n",
    "    project_run_ids = []\n",
    "    for run_id in run_ids:\n",
    "        if run_id.startswith(\"*\"):\n",
    "            # Get limit, if limit is set get the most recent runs\n",
    "            if len(run_id) > 2 and run_id[1] == \":\":\n",
    "                limit = int(run_id.split(\":\")[1])\n",
    "            # Get all runs of the project\n",
    "            project_run_ids = []\n",
    "            print(f\"Getting run id's for project {project}\")\n",
    "            for run in all_project_runs if not limit else all_project_runs[:limit]:\n",
    "                project_run_ids.append(run)\n",
    "            print(f\"Found {len(project_run_ids)} runs\")\n",
    "        elif run_id in all_project_runs:\n",
    "            project_run_ids.append(run_id)\n",
    "            all_non_special_used_run_ids.append(run_id)\n",
    "\n",
    "    for run_id in project_run_ids:\n",
    "        print(f\"Checking run {run_id}\")\n",
    "        if summary_key is not None and summary_value is not None:\n",
    "            run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "            # Update the summary\n",
    "            run.summary[summary_key] = summary_value\n",
    "            run.summary.update()\n",
    "\n",
    "            print(f\"Successfully updated summary of run {run_id} with {summary_key}: {summary_value}\")\n",
    "\n",
    "        # Push best Validation Accuracy * and Validation Distance and Validation Loss to summary\n",
    "        # Technically, this is different from pushing it after training, because there it will use the values of the best epoch, however, this is a good approximation\n",
    "        if push_best:\n",
    "            run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "            # Skip if the run is running\n",
    "            if run.state == \"running\":\n",
    "                print(f\"Run {run_id} is still running, skipping\")\n",
    "                continue\n",
    "            # Get all metrics in summary that start with \"Validation\"\n",
    "            metrics = run.summary.keys()\n",
    "            validation_metrics = [k for k in metrics if k.lower().startswith(\"validation\")]\n",
    "            best_validation_metrics = {}\n",
    "            # For every validation metric, push the best value from the history\n",
    "            for metric in validation_metrics:\n",
    "                best_key = f\"Best {metric}\"\n",
    "                if best_key in metrics and not force_recalculate:\n",
    "                    continue\n",
    "                all_values = run.history()[metric]  # numpy array\n",
    "                all_values_without_nan = all_values[~np.isnan(all_values)]\n",
    "                if len(all_values_without_nan) > 0:\n",
    "                    best_value = np.max(all_values_without_nan) if \"accuracy\" in metric.lower() or \"correct\" in metric.lower() else np.min(all_values_without_nan)\n",
    "                else:\n",
    "                    best_value = np.nan\n",
    "                best_validation_metrics[best_key] = best_value\n",
    "                # Update the summary\n",
    "                run.summary[best_key] = best_value\n",
    "            if len(best_validation_metrics) > 0:\n",
    "                run.summary.update()\n",
    "                print(f\"Successfully updated summary of run {run_id} with {best_validation_metrics}\")\n",
    "            else:\n",
    "                print(f\"Skipped updating summary of run {run_id}\")\n",
    "\n",
    "non_special_run_ids = set([run_id for run_id in run_ids if not run_id.startswith(\"*\")])\n",
    "all_non_special_used_run_ids = set(all_non_special_used_run_ids)\n",
    "if len(non_special_run_ids) > len(all_non_special_used_run_ids):\n",
    "    print(f\"Run ids that were not found: {non_special_run_ids - all_non_special_used_run_ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

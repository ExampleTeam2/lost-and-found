{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting run id's for project dspro2-predicting-country\n",
      "Found 10 runs\n",
      "Checking run kth52fnv\n",
      "Successfully updated summary of run kth52fnv with {'Best Validation Accuracy Top 5': 0.8779091605691363, 'Best Validation Loss': 1.4306674492495821, 'Best Validation Accuracy Top 1': 0.6238261940892769, 'Best Validation Accuracy Top 3': 0.8143996874859143}\n",
      "Checking run 8pqe6jmh\n",
      "Successfully updated summary of run 8pqe6jmh with {'Best Validation Accuracy Top 3': 0.7875054464594258, 'Best Validation Accuracy Top 1': 0.5845816367925237, 'Best Validation Accuracy Top 5': 0.8600147242213441, 'Best Validation Loss': 1.4939452675147338}\n",
      "Checking run ewnspxxj\n",
      "Successfully updated summary of run ewnspxxj with {'Best Validation Accuracy Top 3': 0.7823369442733297, 'Best Validation Accuracy Top 5': 0.8547710984569618, 'Best Validation Accuracy Top 1': 0.5754616343885692, 'Best Validation Loss': 1.5119558592918878}\n",
      "Checking run bc69qzqh\n",
      "Successfully updated summary of run bc69qzqh with {'Best Validation Accuracy Top 3': 0.8262391634238322, 'Best Validation Accuracy Top 5': 0.8834382559310066, 'Best Validation Accuracy Top 1': 0.6489625433838665, 'Best Validation Loss': 1.4016193326946662}\n",
      "Checking run lut8xwlh\n",
      "Successfully updated summary of run lut8xwlh with {'Best Validation Loss': 1.6171948381617098, 'Best Validation Accuracy Top 3': 0.7760126582278482, 'Best Validation Accuracy Top 1': 0.5370886075949367, 'Best Validation Accuracy Top 5': 0.8587341772151899}\n",
      "Checking run uv475hdd\n",
      "Successfully updated summary of run uv475hdd with {'Best Validation Loss': 1.563238747512238, 'Best Validation Accuracy Top 1': 0.6318354430379747, 'Best Validation Accuracy Top 3': 0.839746835443038, 'Best Validation Accuracy Top 5': 0.900506329113924}\n",
      "Checking run fw1ew8lf\n",
      "Successfully updated summary of run fw1ew8lf with {'Best Validation Accuracy Top 1': 0.5509493670886076, 'Best Validation Accuracy Top 3': 0.7813291139240506, 'Best Validation Accuracy Top 5': 0.8577215189873417, 'Best Validation Loss': 1.6736257272430612}\n",
      "Checking run i3x0x8x4\n",
      "Successfully updated summary of run i3x0x8x4 with {'Best Validation Accuracy Top 5': 0.8158721096203254, 'Best Validation Accuracy Top 1': 0.542782877834037, 'Best Validation Accuracy Top 3': 0.7427468185164596, 'Best Validation Loss': 1.723781959897726}\n",
      "Checking run o3liot8x\n",
      "Skipped updating summary of run o3liot8x\n",
      "Checking run shxxwknf\n",
      "Skipped updating summary of run shxxwknf\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "# Log in to WandB\n",
    "wandb.login()\n",
    "\n",
    "# Replace with your entity, project, and run ID\n",
    "entity = \"nlp_ls\"\n",
    "projects = [\"dspro2-predicting-country\", \"dspro2-predicting-region\", \"dspro2-predicting-coordinates\"]\n",
    "run_ids = \"*:10\"  # or [...]\n",
    "\n",
    "# Value to add to the summary\n",
    "summary_key = None  # \"test_data_run_id\"\n",
    "summary_value = None  # \"w1098m89\"\n",
    "\n",
    "# Push best Validation Accuracy * and Validation Distance and Validation Loss as Logs\n",
    "push_best = True\n",
    "force_recalculate = True\n",
    "\n",
    "# Access the run\n",
    "api = wandb.Api()\n",
    "for project in projects:\n",
    "    project_run_ids = run_ids\n",
    "    if project_run_ids[0] != \"*\":\n",
    "        # Get limit, if limit is set get the most recent runs\n",
    "        if len(project_run_ids) > 2 and project_run_ids[1] == \":\":\n",
    "            limit = int(project_run_ids.split(\":\")[1])\n",
    "        # Get all runs of the project\n",
    "        project_run_ids = []\n",
    "        print(f\"Getting run id's for project {project}\")\n",
    "        for run in api.runs(f\"{entity}/{project}\") if not limit else api.runs(f\"{entity}/{project}\")[:limit]:\n",
    "            project_run_ids.append(run.id)\n",
    "        print(f\"Found {len(project_run_ids)} runs\")\n",
    "    for run_id in project_run_ids:\n",
    "        print(f\"Checking run {run_id}\")\n",
    "        if summary_key is not None and summary_value is not None:\n",
    "            run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "            # Update the summary\n",
    "            run.summary[summary_key] = summary_value\n",
    "            run.summary.update()\n",
    "\n",
    "            print(f\"Successfully updated summary of run {run_id} with {summary_key}: {summary_value}\")\n",
    "\n",
    "        # Push best Validation Accuracy * and Validation Distance and Validation Loss to summary\n",
    "        # Technically, this is different from pushing it after training, because there it will use the values of the best epoch, however, this is a good approximation\n",
    "        if push_best:\n",
    "            run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "            # Get all metrics in summary that start with \"Validation\"\n",
    "            metrics = run.summary.keys()\n",
    "            validation_metrics = [k for k in metrics if k.lower().startswith(\"validation\")]\n",
    "            best_validation_metrics = {}\n",
    "            # For every validation metric, push the best value from the history\n",
    "            for metric in validation_metrics:\n",
    "                best_key = f\"Best {metric}\"\n",
    "                if best_key in metrics and not force_recalculate:\n",
    "                    continue\n",
    "                all_values = run.history()[metric]  # numpy array\n",
    "                all_values_without_nan = all_values[~np.isnan(all_values)]\n",
    "                if len(all_values_without_nan) > 0:\n",
    "                    best_value = np.max(all_values_without_nan) if \"accuracy\" in metric.lower() or \"correct\" in metric.lower() else np.min(all_values_without_nan)\n",
    "                else:\n",
    "                    best_value = np.nan\n",
    "                best_validation_metrics[best_key] = best_value\n",
    "                # Update the summary\n",
    "                run.summary[best_key] = best_value\n",
    "            if len(best_validation_metrics) > 0:\n",
    "                run.summary.update()\n",
    "                print(f\"Successfully updated summary of run {run_id} with {best_validation_metrics}\")\n",
    "            else:\n",
    "                print(f\"Skipped updating summary of run {run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from geo_model_tester import GeoModelTester\n",
    "from image_data_handler_test import TestImageDataHandler\n",
    "from best_run_loader import BestRunLoader\n",
    "from wandb_downloader import WandbDownloader\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")\n",
    "# Define where to run\n",
    "env_path = \"../../.env\"\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "\n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files from wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluki-st\u001b[0m (\u001b[33mnlp_ls\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dspro2-predicting-coordinates: Found 5 matching runs for datasize 79000 and base_augmentation.\n"
     ]
    }
   ],
   "source": [
    "# Setting for the right models to test\n",
    "entity = \"nlp_ls\"\n",
    "predict_coordinates = True\n",
    "predict_regions = False\n",
    "datasize = 79000  # 79000, 81505, 332786\n",
    "data_augmentation = \"base_augmentation\"  # or \"base_augmentation\", \"full_augmentation_v2\"\n",
    "\n",
    "# Automatic settings\n",
    "project = \"dspro2-predicting-region\" if predict_regions else (\"dspro2-predicting-coordinates\" if predict_coordinates else \"dspro2-predicting-country\")\n",
    "metric_name = \"Best Validation Accuracy Top 1\" if not predict_coordinates else \"Best Validation Distance (km)\"\n",
    "metric_ascending = False if not predict_coordinates else True\n",
    "file_names_to_download = [\".pth\", \".json\"]\n",
    "image_size = [180, 320] if datasize == 79000 else [80, 130]\n",
    "\n",
    "downloader = WandbDownloader(entity, project, data_augmentation, datasize, image_size)\n",
    "run_data = downloader.get_and_collect_best_runs(metric_name, file_names_to_download, metric_ascending=metric_ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Run 1: exougvwu\n",
      "Best Validation Distance (km):  1728.0912050657637\n",
      "\n",
      "Best Run 2: p8c19p2b\n",
      "Best Validation Distance (km):  1772.2241365456882\n",
      "\n",
      "Best Run 3: c4q2lu4k\n",
      "Best Validation Distance (km):  2257.713803834553\n",
      "\n",
      "Best Run 4: aira59xx\n",
      "Best Validation Distance (km):  2265.0758164804192\n"
     ]
    }
   ],
   "source": [
    "# Print the validation accuracy for the top 1, 3, and 5 predictions\n",
    "for j in range(1, min(len(run_data), 6)):\n",
    "    print(f\"\\nBest Run {j}: {run_data[f'Best Run {j}']['id']}\")\n",
    "    if predict_coordinates:\n",
    "        print(f\"Best Validation Distance (km): \", run_data[f\"Best Run {j}\"][\"metrics\"][\"Best Validation Distance (km)\"])\n",
    "    else:\n",
    "        for i in [1, 3, 5]:\n",
    "            try:\n",
    "                print(f\"Best Validation Accuracy Top {i}: \", run_data[f\"Best Run {j}\"][\"metrics\"][f\"Best Validation Accuracy Top {i}\"])\n",
    "            except KeyError:\n",
    "                print(\"No validation accuracy found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'epochs': 25,\n",
       " 'optimizer': 'adamW',\n",
       " 'batch_size': 200,\n",
       " 'model_name': 'efficientnet_b1',\n",
       " 'mapped_data': True,\n",
       " 'dataset_size': 79000,\n",
       " 'weight_decay': 0.01,\n",
       " 'learning_rate': 0.01,\n",
       " 'predict_regions': False,\n",
       " 'input_image_size': [180, 320],\n",
       " 'data_augmentation': 'base_augmentation',\n",
       " 'different_regions': 4596,\n",
       " 'dataset_identifier': '3d999c168bedf247468b758771d441ecfd202c97836bed006c225a4afbc8688a',\n",
       " 'different_countries': 75,\n",
       " 'predict_coordinates': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_data[\"Best Run 1\"][\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wandb_manifest.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/artifact/930302181/wandb_manifest.json',\n",
       " 'best_model': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/best_model_checkpointmodel_efficientnet_b1_lr_0.01_opt_adamW_weightDecay_0.01_imgSize_[180, 320]_predict_coordinates_True.pth',\n",
       " 'country_to_index.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/country_to_index.json',\n",
       " 'region_index_to_country_index.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/region_index_to_country_index.json',\n",
       " 'region_index_to_middle_point.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/region_index_to_middle_point.json',\n",
       " 'region_to_index.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/region_to_index.json',\n",
       " 'test_data.pth': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/test_data.pth',\n",
       " 'wandb-metadata.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/wandb-metadata.json',\n",
       " 'wandb-summary.json': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/wandb-summary.json',\n",
       " 'test_data': 'https://api.wandb.ai/files/nlp_ls/dspro2-predicting-coordinates/exougvwu/run-20240626_145657-exougvwu/test_data.pth'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_data[\"Best Run 1\"][\"files\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and creating data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 75 countries.\n",
      "Loaded 4596 regions.\n",
      "Loaded 4596 region middle points.\n",
      "Loaded 2676 region to country index mappings.\n",
      "Loading test data from test_data.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...: 100%|██████████| 5.46G/5.46G [03:41<00:00, 24.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded.\n",
      "Caching test data to run-20240626_145657-exougvwu/test_data.pth\n",
      "Test data cached.\n"
     ]
    }
   ],
   "source": [
    "cache = True\n",
    "\n",
    "run = None\n",
    "\n",
    "for i in range(min(len(run_data), 5)):\n",
    "    run = run_data[f\"Best Run {i+1}\"]\n",
    "    if run[\"files\"].get(\"test_data\", None) and run[\"files\"].get(\"best_model\", None):\n",
    "        break\n",
    "    else:\n",
    "        run = None\n",
    "        print(f\"Run {i+1} does not contain the necessary files. Trying the next run...\")\n",
    "\n",
    "if run is None:\n",
    "    raise Exception(\"No run with the necessary files found.\")\n",
    "\n",
    "# Creating Dataloaders with the classes\n",
    "test_dataset = run[\"files\"][\"test_data\"]\n",
    "files = run[\"files\"]\n",
    "country_to_index = files.get(\"country_to_index.json\", None)\n",
    "region_to_index = files.get(\"region_to_index.json\", None)\n",
    "region_index_to_middle_point = files.get(\"region_index_to_middle_point.json\", None)\n",
    "region_index_to_country_index = files.get(\"region_index_to_country_index.json\", None)\n",
    "\n",
    "data_handler = TestImageDataHandler(test_dataset, country_to_index, region_to_index, region_index_to_middle_point, region_index_to_country_index, cache=cache)\n",
    "test_dataloader = data_handler.test_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "region_to_index = data_handler.region_to_index\n",
    "region_index_to_middle_point = data_handler.region_index_to_middle_point\n",
    "region_index_to_country_index = data_handler.region_index_to_country_index\n",
    "\n",
    "num_regions = data_handler.num_regions\n",
    "num_countries = data_handler.num_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3 if predict_coordinates else (num_regions if predict_regions else num_countries)\n",
    "\n",
    "if num_classes == 0:\n",
    "    raise ValueError(\"No classes detected. Please check the data.\")\n",
    "\n",
    "geo_model_tester = GeoModelTester(test_dataloader=test_dataloader, num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index, region_to_index=region_to_index, region_index_to_middle_point=region_index_to_middle_point, region_index_to_country_index=region_index_to_country_index, predict_regions=predict_regions if not predict_coordinates else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network-Model: efficientnet_b1\n",
      "Project Name: coordinates\n",
      "Run ID: exougvwu\n",
      "Test Loss: 2808767.5680, Test Distance: 1891.5918, Test Distance Median: 870.0315\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test the model from best runs\n",
    "# TODO: Show the different models with the best results (also do it for different data sizes and mapped/non-mapped data)\n",
    "model_name = run[\"parameters\"][\"model_name\"]\n",
    "pretrained_weights = run[\"files\"][\"best_model\"]\n",
    "\n",
    "# Countries from 81k more mapped dataset, keep in sync with evaluating_models.ipynb\n",
    "countries_only = [\"Albania\", \"Argentina\", \"Australia\", \"Austria\", \"Bangladesh\", \"Belgium\", \"Bolivia, Plurinational State of\", \"Botswana\", \"Brazil\", \"Bulgaria\", \"Cambodia\", \"Canada\", \"Chile\", \"Colombia\", \"Croatia\", \"Czechia\", \"Denmark\", \"Dominican Republic\", \"Ecuador\", \"Estonia\", \"Eswatini\", \"Finland\", \"France\", \"Germany\", \"Ghana\", \"Greece\", \"Guatemala\", \"Hungary\", \"India\", \"Indonesia\", \"Ireland\", \"Israel\", \"Italy\", \"Japan\", \"Kenya\", \"Korea, Republic of\", \"Kyrgyzstan\", \"Lao People's Democratic Republic\", \"Latvia\", \"Lesotho\", \"Lithuania\", \"Malaysia\", \"Malta\", \"Mexico\", \"Montenegro\", \"Netherlands\", \"New Zealand\", \"Nigeria\", \"North Macedonia\", \"Norway\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\", \"Rwanda\", \"Senegal\", \"Serbia\", \"Singapore\", \"Slovakia\", \"Slovenia\", \"South Africa\", \"Spain\", \"Sri Lanka\", \"Sweden\", \"Switzerland\", \"Thailand\", \"T\\u00fcrkiye\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\", \"United States\", \"Uruguay\"]\n",
    "\n",
    "geo_model_tester.test(model_type=model_name, model_path=pretrained_weights, balanced_on_countries_only=countries_only, accuracy_per_country=False)\n",
    "\n",
    "if not predict_coordinates:\n",
    "    # And over all countries\n",
    "    geo_model_tester.test(model_type=model_name, model_path=pretrained_weights, balanced_on_countries_only=None, accuracy_per_country=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "from geo_model_trainer import GeoModelTrainer\n",
    "from image_data_handler import ImageDataHandler\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from data_loader import get_data_to_load, hash_filenames\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")\n",
    "# Define where to run\n",
    "env_path = \"../../.env\"\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "\n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on which gpu to run with best settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"nlp_ls\"\n",
    "\n",
    "original_image_size = [180, 320]\n",
    "\n",
    "NUMBER_OF_FILES = 0\n",
    "BATCH_SIZE = 400\n",
    "USE_MAPPED = True\n",
    "\n",
    "running_device = \"colab_T4\"\n",
    "image_size = [80, 130]\n",
    "data_augmentation = \"full_augmentation_v2\"  # or \"base_augmentation\", \"full_augmentation_v2\"\n",
    "predict_coordinates = True\n",
    "predict_regions = False\n",
    "\n",
    "if running_device == \"colab_T4\":\n",
    "    # Run unmapped images with low image resolution on colab\n",
    "    BATCH_SIZE = 300\n",
    "    USE_MAPPED = False\n",
    "\n",
    "elif running_device == \"colab_A100\":\n",
    "    # Run mapped images with high image resolution on colab\n",
    "    image_size = original_image_size\n",
    "    BATCH_SIZE = 200\n",
    "    NUMBER_OF_FILES = 79000\n",
    "\n",
    "elif running_device == \"gpuHub\":\n",
    "    # Run unmapped images with low image resolution on gpuHub\n",
    "    BATCH_SIZE = 200\n",
    "    USE_MAPPED = False\n",
    "\n",
    "elif running_device == \"gpuHub_augmentedv2\":\n",
    "    # Run unmapped images with low image resolution on gpuHub\n",
    "    BATCH_SIZE = 100\n",
    "    USE_MAPPED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping remote files check\n",
      "All local files: 705681\n",
      "Relevant files: 705681\n"
     ]
    }
   ],
   "source": [
    "# get list with local data and file paths\n",
    "list_files, load_callback, additional_save_callback = get_data_to_load(loading_file=\"../3_data_preparation/04_data_cleaning/updated_data_list_more\" if USE_MAPPED else \"../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped\", file_location=\"../3_data_preparation/01_enriching/.data\", image_file_location=\"../1_data_collection/.data\", allow_new_file_creation=False, from_remote_only=True, download_link=\"default\", limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, allow_image_file_location_env=True, allow_download_link_env=True, return_load_and_additional_save_callback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "# Get directory of the first file\n",
    "first_file = list_files[0]\n",
    "first_file_dir = os.path.dirname(first_file)[:-4]\n",
    "# Get all files in the same directory\n",
    "files_in_dir = [os.path.join(first_file_dir, f) for f in os.listdir(first_file_dir) if os.path.isfile(os.path.join(first_file_dir, f))]\n",
    "# Get basenames of all files\n",
    "basenames_list = [os.path.basename(f) for f in list_files]\n",
    "basenames = [os.path.basename(f) for f in files_in_dir]\n",
    "# Create a set of basenames\n",
    "basenames_list_set = set(basenames_list)\n",
    "basenames_set = set(basenames)\n",
    "# Get all basenames that are in basenames_set but not in basenames_list_set\n",
    "missing_files = basenames_set - basenames_list_set\n",
    "# Delete the files that are missing\n",
    "for missing_file in missing_files:\n",
    "    if missing_file.startswith(\"geoguessr\"):\n",
    "        missing_file = files_in_dir[basenames.index(missing_file)]\n",
    "        os.remove(missing_file)\n",
    "json_files = [file for file in list_files if file.endswith(\".json\")]\n",
    "image_files = [file for file in list_files if file.endswith(\".png\")]\n",
    "for index, file in enumerate(json_files):\n",
    "    # Rename to \"location_<count(with leading 0 up to 6 digits)>.json\n",
    "    os.replace(file, os.path.join(first_file_dir, f\"location_{index:06d}.json\"))\n",
    "for index, file in enumerate(image_files):\n",
    "    # Rename to \"location_<count(with leading 0 up to 6 digits)>.png\n",
    "    os.replace(file, os.path.join(first_file_dir, f\"location_{index:06d}.png\"))\n",
    "# Delete the files that are not .json or .png\n",
    "for file in os.listdir(first_file_dir):\n",
    "    file = os.path.join(first_file_dir, file)\n",
    "    if not (file.endswith(\".png\") or file.endswith(\".json\")):\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "        elif os.path.isdir(file):\n",
    "            shutil.rmtree(file)\n",
    "# Create a data.zip file\n",
    "os.system(f\"cd {first_file_dir} && zip -qr data.zip .\")\n",
    "# Copy the data.zip file to /content/drive/MyDrive/\n",
    "os.system(f\"cp {first_file_dir}/data.zip /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81505\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_FILES = len(list_files) // 2\n",
    "print(NUMBER_OF_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type = \"regions\" if predict_regions else (\"coordinates\" if predict_coordinates else \"countries\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "preprocessing_config = {\"data_augmentation\": data_augmentation, \"height\": image_size[0], \"width\": image_size[1], \"train_ratio\": train_ratio, \"val_ratio\": val_ratio, \"test_ratio\": test_ratio}\n",
    "\n",
    "augmented_transform = None  # Happens before base_transform\n",
    "base_transform = transforms.Compose([transforms.Resize((image_size[0], image_size[1])), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "if data_augmentation == \"full_augmentation_v2\":\n",
    "    # Happens before base_transform\n",
    "    augmented_transform = transforms.Compose(\n",
    "        [\n",
    "            # Disabled because black bars really hurt the performance at this size (only for v2)\n",
    "            # transforms.RandomPerspective(distortion_scale=0.75, p=0.5),  # Randomly apply perspective transformation\n",
    "            transforms.RandomResizedCrop((original_image_size[0], original_image_size[1]), scale=(0.75, 1.0)),  # Randomly crop the image and resize it to the original size\n",
    "            transforms.RandomRotation(10),  # Randomly rotate the image by up to 10 degrees, sadly also causes black borders\n",
    "            transforms.ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=(0.5, 1.5), hue=(-0.1, 0.1)),  # Randomly change brightness (lower limit to simulate night, upper limit for bright daylight)  # Randomly change contrast  # Randomly change saturation  # Randomly change hue\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a notebook.\n",
      "Using cached data from: data_81505_data_augmentation=base_augmentationheight=1test_ratio=0.1train_ratio=0.7val_ratio=0.2width=1&63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c.pth\n",
      "Data loaded.\n",
      "Creating new run link at run_81505_data_augmentation=base_augmentationheight=1test_ratio=0.1train_ratio=0.7val_ratio=0.2width=1&63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c.wandb\n",
      "Saving test data to test_data.pth\n",
      "Test data saved.\n",
      "Dataset size: 81505\n",
      "Dataset identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "Count of different countries: 75\n",
      "Count of different regions: 4596\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "\n",
    "# Hash the files list to get a unique identifier for the data\n",
    "hashed_filenames = hash_filenames(list_files)\n",
    "\n",
    "cache = True\n",
    "move_files = False\n",
    "# Move .pth and .zip files instead of copying them, could cause issues but saves space and should be fine\n",
    "\n",
    "# Check if the code is running in a notebook\n",
    "running_in_notebook = False\n",
    "try:\n",
    "    get_ipython()\n",
    "    running_in_notebook = True\n",
    "    print(\"Running in a notebook.\")\n",
    "except NameError:\n",
    "    print(\"Running in a script.\")\n",
    "\n",
    "data_handler = ImageDataHandler(list_files, augmented_transform, base_transform, preprocessing_config, prediction_type, batch_size=BATCH_SIZE, train_ratio=train_ratio, val_ratio=val_ratio, test_ratio=test_ratio, cache=cache, cache_load_callback=load_callback, cache_additional_save_callback=additional_save_callback, save_test_data=True, inspect_transformed=running_in_notebook and (data_augmentation == \"full_augmentation_v2\"), move_files=move_files, get_cache=True)\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "region_to_index = data_handler.region_to_index\n",
    "region_index_to_middle_point = data_handler.region_index_to_middle_point\n",
    "region_index_to_country_index = data_handler.region_index_to_country_index\n",
    "# Path of test data if it should be pushed to wandb\n",
    "test_data_path = data_handler.test_data_path\n",
    "# Previous run id if the test data was already pushed to wandb (to save space)\n",
    "run_link = data_handler.run_link\n",
    "# Path to the run link file to be created if it was not previously (if test data should be pushed)\n",
    "run_link_path = data_handler.run_link_path\n",
    "\n",
    "# Load the country_to_index mapping and print the count of different countries\n",
    "print(\"Dataset size:\", NUMBER_OF_FILES)\n",
    "print(\"Dataset identifier:\", hashed_filenames)\n",
    "print(f\"Count of different countries: {len(country_to_index)}\")\n",
    "print(f\"Count of different regions: {len(region_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 57053 \n",
      "Images batch shape: torch.Size([200, 3, 1, 1])\n",
      "Coordinates batch shape: torch.Size([200, 2])\n",
      "tensor([12.9247, 77.8241])\n",
      "Country indices: torch.Size([200])\n",
      "tensor(28)\n",
      "Region handler: torch.Size([200])\n",
      "tensor(1476)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices, region_indices in train_dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "    print(coordinates[0])\n",
    "    print(\"Country indices:\", country_indices.shape)\n",
    "    print(country_indices[0])\n",
    "    print(\"Region handler:\", region_indices.shape)\n",
    "    print(region_indices[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkillusions\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: azze6syd\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ifp48yu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: efficientnet_b1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/linus/gitprojects/dspro2/dspro2/4_modeling/wandb/run-20240620_231957-ifp48yu5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">splendid-sweep-1</a></strong> to <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8r6jm1p1\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/8r6jm1p1\n",
      "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvae6ird with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: mobilenet_v2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"
     ]
    }
   ],
   "source": [
    "model_types = [\"resnet50\", \"efficientnet_b3\"]  # \"efficientnet_b1\", \"resnet50\", \"mobilenet_v2\"\n",
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()\n",
    "\n",
    "for model_type in model_types:\n",
    "    if predict_coordinates:\n",
    "        project_name = \"predicting-coordinates\"\n",
    "        num_classes = 3\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    elif predict_regions:\n",
    "        project_name = \"predicting-region\"\n",
    "        num_classes = len(region_to_index)\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    else:\n",
    "        num_classes = len(country_to_index)\n",
    "        project_name = \"predicting-country\"\n",
    "        sweep_goal = \"maximize\"\n",
    "        sweep_metric_name = \"Validation Accuracy Top 1\"\n",
    "\n",
    "    sweep_config = {\n",
    "        \"name\": f\"dspro2-basemodel-{model_type}-datasize-{NUMBER_OF_FILES}-input_imagesize-{image_size[0]}x{image_size[1]}\",\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": sweep_goal, \"name\": sweep_metric_name},\n",
    "        # fmt: off\n",
    "        \"parameters\": {\"learning_rate\": {\"values\": [1e-3]}, \n",
    "                       \"optimizer\": {\"values\": [\"adamW\"]}, \"weight_decay\": {\"values\": [0, 1e-1, 1e-2, 1e-3]}, \n",
    "                       \"epochs\": {\"values\": [20]}, \"dataset_size\": {\"values\": [NUMBER_OF_FILES]}, \n",
    "                       \"dataset_identifier\": {\"values\": [hashed_filenames]}, \n",
    "                       \"seed\": {\"values\": [42]}, \n",
    "                       \"model_name\": {\"values\": [model_type]}, \n",
    "                       \"input_image_size\": {\"values\": [image_size]}, \n",
    "                       \"predict_coordinates\": {\"values\": [predict_coordinates]}, \n",
    "                       \"mapped_data\": {\"values\": [USE_MAPPED]}, \n",
    "                       \"different_countries\": {\"values\": [len(country_to_index) if country_to_index is not None else 0]}, \n",
    "                       \"different_regions\": {\"values\": [len(region_to_index) if region_to_index is not None else 0]}, \n",
    "                       \"data_augmentation\": {\"values\": [data_augmentation]}, \n",
    "                       \"predict_regions\": {\"values\": [predict_regions]}, \n",
    "                       \"batch_size\": {\"values\": [BATCH_SIZE]}},\n",
    "        # fmt: on\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-{project_name}\", entity=entity)\n",
    "\n",
    "    def set_run_link(config, run):\n",
    "        global run_link\n",
    "        global run_link_path\n",
    "        if run_link_path is not None:\n",
    "            run_link = run.id\n",
    "            with open(run_link_path, \"w\") as f:\n",
    "                f.write(run_link)\n",
    "            # Only write once\n",
    "            run_link_path = None\n",
    "            if additional_save_callback is not None:\n",
    "                additional_save_callback()\n",
    "        elif run_link is not None:\n",
    "            wandb.log({\"test_data_run_id\": run_link})\n",
    "\n",
    "    trainer = GeoModelTrainer(datasize=NUMBER_OF_FILES, train_dataloader=train_dataloader, val_dataloader=val_dataloader, num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index, region_to_index=region_to_index, region_index_to_middle_point=region_index_to_middle_point, region_index_to_country_index=region_index_to_country_index, predict_regions=predict_regions if not predict_coordinates else None, test_data_path=test_data_path, run_start_callback=set_run_link)\n",
    "\n",
    "    wandb.agent(sweep_id, function=trainer.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

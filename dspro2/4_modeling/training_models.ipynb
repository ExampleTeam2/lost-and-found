{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "from geo_model_trainer import GeoModelTrainer\n",
    "from image_data_handler import ImageDataHandler\n",
    "\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, hash_filenames\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv('WANDB_TOKEN')\n",
    "# Define where to run\n",
    "env_path = '../../.env'\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "  load_dotenv(env_path)\n",
    "  WANDB_TOKEN = os.getenv('WANDB_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping remote files check\n",
      "All local files: 705681\n",
      "Relevant files: 705681\n",
      "Limited files: 158000\n"
     ]
    }
   ],
   "source": [
    "# set number of files to load\n",
    "NUMBER_OF_FILES = 79000 # 100000\n",
    "# Set to False to use non-mapped data (singleplayer distribution), has more data\n",
    "USE_MAPPED = True\n",
    "\n",
    "# get list with local data and file paths\n",
    "list_files, zip_load_callback, pth_save_callback = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list_more' if USE_MAPPED else '../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped', \n",
    "                              file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, \n",
    "                              from_remote_only=True, download_link='default', limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, \n",
    "                              allow_image_file_location_env=True, allow_download_link_env=True, return_zip_load_and_pth_save_callback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79000\n"
     ]
    }
   ],
   "source": [
    "print(len(list_files) // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = \"full_augmentation\"\n",
    "\n",
    "# Default was 50, 50\n",
    "image_size = [80, 130]\n",
    "# Original size is  pixelHeight: 180, pixelWidth: 320\n",
    "# image_size = [180, 320]\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "preprocessing_config = { 'data_augmentation': data_augmentation, 'height': image_size[0], 'width': image_size[1], 'train_ratio': train_ratio, 'val_ratio': val_ratio, 'test_ratio': test_ratio }\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "          transforms.Resize((image_size[0], image_size[1])),\n",
    "        ])\n",
    "augmented_transform = None\n",
    "final_transform = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "if data_augmentation == \"full_augmentation\":\n",
    "    augmented_transform = transforms.Compose([\n",
    "        transforms.RandomPerspective(distortion_scale=0.75, p=0.5),  # Randomly apply perspective transformation\n",
    "        transforms.RandomResizedCrop((image_size[0], image_size[1]), scale=(0.75, 1.0)),  # Randomly crop the image and resize it to the original size\n",
    "        transforms.RandomRotation(10),          # Randomly rotate the image by up to 10 degrees\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),  # Randomly change brightness (lower limit to simulate night, upper limit for bright daylight)\n",
    "            contrast=(0.5, 1.5),    # Randomly change contrast\n",
    "            saturation=(0.5, 1.5),  # Randomly change saturation\n",
    "            hue=(-0.1, 0.1)         # Randomly change hue\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data from: data_79000_data_augmentation=base_augmentationheight=80test_ratio=0.1train_ratio=0.7val_ratio=0.2width=130&3d999c168bedf247468b758771d441ecfd202c97836bed006c225a4afbc8688a.pth\n",
      "Data loaded.\n",
      "Saving test data to test_data.pth\n",
      "Test data saved.\n",
      "Dataset size: 79000\n",
      "Dataset identifier: 3d999c168bedf247468b758771d441ecfd202c97836bed006c225a4afbc8688a\n",
      "Count of different countries: 75\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "\n",
    "# Hash the files list to get a unique identifier for the data\n",
    "hashed_filenames = hash_filenames(list_files)\n",
    "\n",
    "cache = True\n",
    "\n",
    "data_handler = ImageDataHandler(list_files, base_transform, augmented_transform, final_transform, preprocessing_config, batch_size=200, train_ratio=train_ratio, val_ratio=val_ratio, test_ratio=test_ratio, cache=cache, cache_zip_load_callback=zip_load_callback, cache_pth_save_callback=pth_save_callback, save_test_data=True)\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "test_data_path = data_handler.test_data_path\n",
    "\n",
    "# Load the country_to_index mapping and print the count of different countries\n",
    "print(\"Dataset size:\", NUMBER_OF_FILES)\n",
    "print(\"Dataset identifier:\", hashed_filenames)\n",
    "print(f\"Count of different countries: {len(country_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 55300 \n",
      "Images batch shape: torch.Size([200, 3, 80, 130])\n",
      "Coordinates batch shape: torch.Size([200, 2])\n",
      "tensor([-37.7433, 144.9500])\n",
      "Country indices: torch.Size([200])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices in train_dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "    print(coordinates[0])\n",
    "    print(\"Country indices:\", country_indices.shape)\n",
    "    print(country_indices[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"efficientnet_b1\", \"mobilenet_v2\", \"resnet18\", \"efficientnet_b3\", \"resnet50\"]\n",
    "predict_coordinates=False\n",
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()\n",
    "\n",
    "for model_type in model_types:\n",
    "    if predict_coordinates:\n",
    "        project_name = \"predicting-coordinates\"\n",
    "        num_classes = 2\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    else:\n",
    "        num_classes = len(country_to_index)\n",
    "        project_name = \"predicting-country\"\n",
    "        sweep_goal = \"maximize\"\n",
    "        sweep_metric_name = \"Validation Accuracy Top 1\"\n",
    "    \n",
    "    sweep_config = {\n",
    "        \"name\": f\"dspro2-basemodel-{model_type}-datasize-{NUMBER_OF_FILES}-input_imagesize-{image_size[0]}x{image_size[1]}\",\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": sweep_goal, \"name\": sweep_metric_name},\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\"values\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]},\n",
    "            \"optimizer\": {\"values\": [\"adamW\"]},\n",
    "            \"weight_decay\": {\"values\": [1e-1, 1e-2, 1e-3]},\n",
    "            \"epochs\": {\"values\": [50]},\n",
    "            \"dataset_size\": {\"values\": [NUMBER_OF_FILES]},\n",
    "            \"dataset_identifier\": {\"values\": [hashed_filenames]},\n",
    "            \"seed\": {\"values\": [42]},\n",
    "            \"model_name\": {\"values\": [model_type]},\n",
    "            \"input_image_size\": {\"values\": [image_size]},\n",
    "            \"predict_coordinates\": {\"values\": [predict_coordinates]},\n",
    "            \"mapped_data\": {\"values\": [USE_MAPPED]},\n",
    "            \"different_countries\": {\"values\": [len(country_to_index)]},\n",
    "            \"data_augmentation\": {\"values\": [data_augmentation]}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-basemodel-{project_name}\")\n",
    "    trainer = GeoModelTrainer(datasize=NUMBER_OF_FILES, train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                              num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index if not predict_coordinates else None, test_data_path=test_data_path)\n",
    "\n",
    "    wandb.agent(sweep_id, function=trainer.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

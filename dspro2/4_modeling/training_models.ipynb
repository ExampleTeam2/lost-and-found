{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "from geo_model_trainer import GeoModelTrainer\n",
    "from image_data_handler import ImageDataHandler\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, hash_filenames\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv('WANDB_TOKEN')\n",
    "# Define where to run\n",
    "env_path = '../../.env'\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "  load_dotenv(env_path)\n",
    "  WANDB_TOKEN = os.getenv('WANDB_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on which gpu to run with best settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_FILES = 0\n",
    "BATCH_SIZE = 500\n",
    "USE_MAPPED = True\n",
    "\n",
    "running_device = \"cpu\"\n",
    "image_size = [80, 130]\n",
    "data_augmentation = \"base_augmentation\" # or \"base_augmentation\", \"full_augmentation_v2\"\n",
    "predict_coordinates=True\n",
    "predict_regions=False\n",
    "\n",
    "if running_device == \"colab_L4\":\n",
    "    # Run unmapped images with low image resolution\n",
    "    BATCH_SIZE = 400\n",
    "    USE_MAPPED = False\n",
    "\n",
    "elif running_device == \"colab_A100\":\n",
    "    # Run mapped images with high image resolution\n",
    "    image_size = [180, 320]\n",
    "    BATCH_SIZE = 200\n",
    "    NUMBER_OF_FILES = 79000\n",
    "\n",
    "elif running_device == \"cpu\":\n",
    "    # For testing purposes\n",
    "    image_size = [20, 20]\n",
    "    BATCH_SIZE = 200\n",
    "    NUMBER_OF_FILES = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping remote files check\n",
      "All local files: 705681\n",
      "Relevant files: 705681\n"
     ]
    }
   ],
   "source": [
    "# get list with local data and file paths\n",
    "list_files, zip_load_callback, additional_save_callback = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list_more' if USE_MAPPED else '../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped', \n",
    "                              file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, \n",
    "                              from_remote_only=True, download_link='default', limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, \n",
    "                              allow_image_file_location_env=True, allow_download_link_env=True, return_zip_load_and_additional_save_callback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81505\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_FILES = len(list_files) // 2\n",
    "print(NUMBER_OF_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type = \"regions\" if predict_regions else (\"coordinates\" if predict_coordinates else \"countries\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "preprocessing_config = { 'data_augmentation': data_augmentation, 'height': image_size[0], 'width': image_size[1], 'train_ratio': train_ratio, 'val_ratio': val_ratio, 'test_ratio': test_ratio }\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "          transforms.Resize((image_size[0], image_size[1])),\n",
    "        ])\n",
    "augmented_transform = None\n",
    "final_transform = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "if data_augmentation == \"full_augmentation_v2\":\n",
    "    base_transform = transforms.Compose([])\n",
    "    augmented_transform = transforms.Compose([\n",
    "        # Disabled because black bars really hurt the performance at this size (only for v2)\n",
    "        # transforms.RandomPerspective(distortion_scale=0.75, p=0.5),  # Randomly apply perspective transformation\n",
    "        transforms.RandomResizedCrop((image_size[0], image_size[1]), scale=(0.75, 1.0)),  # Randomly crop the image and resize it to the original size\n",
    "        transforms.RandomRotation(10),          # Randomly rotate the image by up to 10 degrees, sadly also causes black borders\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),  # Randomly change brightness (lower limit to simulate night, upper limit for bright daylight)\n",
    "            contrast=(0.5, 1.5),    # Randomly change contrast\n",
    "            saturation=(0.5, 1.5),  # Randomly change saturation\n",
    "            hue=(-0.1, 0.1)         # Randomly change hue\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a notebook.\n",
      "Using cached data from: data_81505_data_augmentation=base_augmentationheight=1test_ratio=0.1train_ratio=0.7val_ratio=0.2width=1&63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c.pth\n",
      "Data loaded.\n",
      "Creating new run link at run_81505_data_augmentation=base_augmentationheight=1test_ratio=0.1train_ratio=0.7val_ratio=0.2width=1&63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c.wandb\n",
      "Saving test data to test_data.pth\n",
      "Test data saved.\n",
      "Dataset size: 81505\n",
      "Dataset identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "Count of different countries: 75\n",
      "Count of different regions: 4596\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "\n",
    "# Hash the files list to get a unique identifier for the data\n",
    "hashed_filenames = hash_filenames(list_files)\n",
    "\n",
    "cache = True\n",
    "\n",
    "# Check if the code is running in a notebook\n",
    "running_in_notebook = False\n",
    "try:\n",
    "  get_ipython()\n",
    "  running_in_notebook = True\n",
    "  print(\"Running in a notebook.\")\n",
    "except NameError:\n",
    "  print(\"Running in a script.\")\n",
    "\n",
    "data_handler = ImageDataHandler(list_files, base_transform, augmented_transform, final_transform, preprocessing_config, prediction_type, batch_size=BATCH_SIZE, train_ratio=train_ratio, val_ratio=val_ratio, test_ratio=test_ratio, cache=cache, cache_zip_load_callback=zip_load_callback, cache_additional_save_callback=additional_save_callback, save_test_data=True, inspect_transformed=running_in_notebook and (data_augmentation == \"full_augmentation_v2\"))\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "region_to_index = data_handler.region_to_index\n",
    "region_index_to_middle_point = data_handler.region_index_to_middle_point\n",
    "region_index_to_country_index = data_handler.region_index_to_country_index\n",
    "# Path of test data if it should be pushed to wandb\n",
    "test_data_path = data_handler.test_data_path\n",
    "# Previous run id if the test data was already pushed to wandb (to save space)\n",
    "run_link = data_handler.run_link\n",
    "# Path to the run link file to be created if it was not previously (if test data should be pushed)\n",
    "run_link_path = data_handler.run_link_path\n",
    "\n",
    "# Load the country_to_index mapping and print the count of different countries\n",
    "print(\"Dataset size:\", NUMBER_OF_FILES)\n",
    "print(\"Dataset identifier:\", hashed_filenames)\n",
    "print(f\"Count of different countries: {len(country_to_index)}\")\n",
    "print(f\"Count of different regions: {len(region_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 57053 \n",
      "Images batch shape: torch.Size([200, 3, 1, 1])\n",
      "Coordinates batch shape: torch.Size([200, 2])\n",
      "tensor([12.9247, 77.8241])\n",
      "Country indices: torch.Size([200])\n",
      "tensor(28)\n",
      "Region handler: torch.Size([200])\n",
      "tensor(1476)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices, region_indices in train_dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "    print(coordinates[0])\n",
    "    print(\"Country indices:\", country_indices.shape)\n",
    "    print(country_indices[0])\n",
    "    print(\"Region handler:\", region_indices.shape)\n",
    "    print(region_indices[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkillusions\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: azze6syd\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ifp48yu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: efficientnet_b1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/linus/gitprojects/dspro2/dspro2/4_modeling/wandb/run-20240620_231957-ifp48yu5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">splendid-sweep-1</a></strong> to <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8r6jm1p1\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/8r6jm1p1\n",
      "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvae6ird with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: mobilenet_v2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"
     ]
    }
   ],
   "source": [
    "model_types = [\"efficientnet_b1\", \"efficientnet_b3\", \"resnet50\", \"mobilenet_v2\"]\n",
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()\n",
    "\n",
    "for model_type in model_types:\n",
    "    if predict_coordinates:\n",
    "        project_name = \"predicting-coordinates\"\n",
    "        num_classes = 3\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    elif predict_regions:\n",
    "        project_name = \"predicting-region\"\n",
    "        num_classes = len(region_to_index)\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    else:\n",
    "        num_classes = len(country_to_index)\n",
    "        project_name = \"predicting-country\"\n",
    "        sweep_goal = \"maximize\"\n",
    "        sweep_metric_name = \"Validation Accuracy Top 1\"\n",
    "        \n",
    "    sweep_config = {\n",
    "        \"name\": f\"dspro2-basemodel-{model_type}-datasize-{NUMBER_OF_FILES}-input_imagesize-{image_size[0]}x{image_size[1]}\",\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": sweep_goal, \"name\": sweep_metric_name},\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\"values\": [1e-1, 1e-2, 1e-3]}, #1e-4, 1e-5\n",
    "            \"optimizer\": {\"values\": [\"adamW\"]},\n",
    "            \"weight_decay\": {\"values\": [1e-2]},\n",
    "            \"epochs\": {\"values\": [50]},\n",
    "            \"dataset_size\": {\"values\": [NUMBER_OF_FILES]},\n",
    "            \"dataset_identifier\": {\"values\": [hashed_filenames]},\n",
    "            \"seed\": {\"values\": [42]},\n",
    "            \"model_name\": {\"values\": [model_type]},\n",
    "            \"input_image_size\": {\"values\": [image_size]},\n",
    "            \"predict_coordinates\": {\"values\": [predict_coordinates]},\n",
    "            \"mapped_data\": {\"values\": [USE_MAPPED]},\n",
    "            \"different_countries\": {\"values\": [len(country_to_index) if country_to_index is not None else 0]},\n",
    "            \"different_regions\": {\"values\": [len(region_to_index) if region_to_index is not None else 0]},\n",
    "            \"data_augmentation\": {\"values\": [data_augmentation]},\n",
    "            \"predict_regions\": {\"values\": [predict_regions]},\n",
    "            \"batch_size\": {\"values\": [BATCH_SIZE]}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-{project_name}\", entity=\"nlp_ls\")\n",
    "    \n",
    "    def set_run_link(config, run):\n",
    "      global run_link\n",
    "      global run_link_path\n",
    "      if run_link_path is not None:\n",
    "        run_link = run.id\n",
    "        with open(run_link_path, 'w') as f:\n",
    "          f.write(run_link)\n",
    "        # Only write once\n",
    "        run_link_path = None\n",
    "        if additional_save_callback is not None:\n",
    "          additional_save_callback()\n",
    "      elif run_link is not None:\n",
    "        wandb.log({\"test_data_run_id\": run_link})\n",
    "    \n",
    "    trainer = GeoModelTrainer(datasize=NUMBER_OF_FILES, train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                              num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index, region_to_index=region_to_index, region_index_to_middle_point=region_index_to_middle_point, region_index_to_country_index=region_index_to_country_index, predict_regions=predict_regions if not predict_coordinates else None, test_data_path=test_data_path, run_start_callback=set_run_link)\n",
    "\n",
    "    wandb.agent(sweep_id, function=trainer.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionally evaluate models after training\n",
    "\n",
    "## Warning: Does not use all values from wandb but data from current project state, make sure they are in sync, otherwise use testing_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "from geo_model_evaluator import GeoModelEvaluator\n",
    "from image_data_handler import ImageDataHandler\n",
    "from wandb_downloader import WandbDownloader\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from data_loader import get_data_to_load, hash_filenames\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")\n",
    "# Define where to run\n",
    "env_path = \"../../.env\"\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "\n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set runs to update (should be of the same project, type and dataset (augmentation, size, ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkillusions\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "project = \"dspro2-predicting-region\"\n",
    "run_ids = [\"kwlp08u6\", \"j3e89vyc\"]  # should all be of the same project, type and dataset (augmentation, size, ...)\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()\n",
    "\n",
    "# Get first run to get the config via the API\n",
    "api = wandb.Api()\n",
    "run = api.run(f\"nlp_ls/{project}/{run_ids[0]}\")\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_FILES = config[\"dataset_size\"]\n",
    "USE_MAPPED = config[\"mapped_data\"]\n",
    "\n",
    "image_size = config[\"input_image_size\"]\n",
    "predict_coordinates = config[\"predict_coordinates\"]\n",
    "predict_regions = config[\"predict_regions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on which gpu to run with best settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 400\n",
    "\n",
    "running_device = \"colab_T4\"\n",
    "\n",
    "if running_device == \"colab_T4\":\n",
    "    # Run unmapped images with low image resolution on colab\n",
    "    BATCH_SIZE = 300\n",
    "\n",
    "elif running_device == \"colab_A100\":\n",
    "    # Run mapped images with high image resolution on colab\n",
    "    BATCH_SIZE = 200\n",
    "\n",
    "elif running_device == \"gpuHub\":\n",
    "    # Run unmapped images with low image resolution on gpuHub\n",
    "    BATCH_SIZE = 200\n",
    "\n",
    "elif running_device == \"gpuHub_augmentedv2\":\n",
    "    # Run unmapped images with low image resolution on gpuHub\n",
    "    BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping remote files check\n",
      "All local files: 705681\n",
      "Relevant files: 705681\n",
      "Limited files: 665572\n"
     ]
    }
   ],
   "source": [
    "# get list with local data and file paths\n",
    "list_files, zip_load_callback, additional_save_callback = get_data_to_load(loading_file=\"../3_data_preparation/04_data_cleaning/updated_data_list_more\" if USE_MAPPED else \"../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped\", file_location=\"../3_data_preparation/01_enriching/.data\", image_file_location=\"../1_data_collection/.data\", allow_new_file_creation=False, from_remote_only=True, download_link=\"default\", limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, allow_image_file_location_env=True, allow_download_link_env=True, return_zip_load_and_additional_save_callback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332786\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_FILES = len(list_files) // 2\n",
    "print(NUMBER_OF_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type = \"regions\" if predict_regions else (\"coordinates\" if predict_coordinates else \"countries\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "data_augmentation = config[\"data_augmentation\"]\n",
    "\n",
    "preprocessing_config = {\"data_augmentation\": data_augmentation, \"height\": image_size[0], \"width\": image_size[1], \"train_ratio\": train_ratio, \"val_ratio\": val_ratio, \"test_ratio\": test_ratio}\n",
    "\n",
    "augmented_transform = None  # Never used in this script\n",
    "base_transform = transforms.Compose([transforms.Resize((image_size[0], image_size[1])), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train images and labels:   0%|          | 0/777 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'regions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating Dataloasders with the classes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Hash the files list to get a unique identifier for the data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m hashed_filenames \u001b[38;5;241m=\u001b[39m hash_filenames(list_files)\n\u001b[0;32m----> 6\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessing_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_zip_load_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_load_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_additional_save_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_save_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minspect_transformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mtrain_loader\n\u001b[1;32m      8\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mval_loader\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../4_modeling/image_data_handler.py:98\u001b[0m, in \u001b[0;36mImageDataHandler.__init__\u001b[0;34m(self, list_files, augmented_transform, base_transform, preprocessing_config, prediction_type, batch_size, train_ratio, val_ratio, test_ratio, cache, cache_zip_load_callback, cache_additional_save_callback, save_test_data, random_seed, inspect_transformed, move_files, get_cache)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_countries\u001b[38;5;241m.\u001b[39mextend([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m labels])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_coordinates\u001b[38;5;241m.\u001b[39mextend([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m labels])\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_regions\u001b[38;5;241m.\u001b[39mextend([\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m labels])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_images\u001b[38;5;241m.\u001b[39mappend(train_transform(image))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'regions'"
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "\n",
    "# Hash the files list to get a unique identifier for the data\n",
    "hashed_filenames = hash_filenames(list_files)\n",
    "\n",
    "data_handler = ImageDataHandler(list_files, augmented_transform, base_transform, preprocessing_config, prediction_type, batch_size=BATCH_SIZE, train_ratio=train_ratio, val_ratio=val_ratio, test_ratio=test_ratio, cache=False, cache_zip_load_callback=zip_load_callback, cache_additional_save_callback=additional_save_callback, save_test_data=False, inspect_transformed=False, move_files=False, get_cache=True)\n",
    "val_dataloader = data_handler.val_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "region_to_index = data_handler.region_to_index\n",
    "region_index_to_middle_point = data_handler.region_index_to_middle_point\n",
    "region_index_to_country_index = data_handler.region_index_to_country_index\n",
    "\n",
    "# Load the country_to_index mapping and print the count of different countries\n",
    "print(\"Dataset size:\", NUMBER_OF_FILES)\n",
    "print(\"Dataset identifier:\", hashed_filenames)\n",
    "print(f\"Count of different countries: {len(country_to_index)}\")\n",
    "print(f\"Count of different regions: {len(region_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 57053 \n",
      "Images batch shape: torch.Size([200, 3, 1, 1])\n",
      "Coordinates batch shape: torch.Size([200, 2])\n",
      "tensor([12.9247, 77.8241])\n",
      "Country indices: torch.Size([200])\n",
      "tensor(28)\n",
      "Region handler: torch.Size([200])\n",
      "tensor(1476)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of val batches:\", len(val_dataloader.dataset), \"\")\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices, region_indices in val_dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "    print(coordinates[0])\n",
    "    print(\"Country indices:\", country_indices.shape)\n",
    "    print(country_indices[0])\n",
    "    print(\"Region handler:\", region_indices.shape)\n",
    "    print(region_indices[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkillusions\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: azze6syd\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ifp48yu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: efficientnet_b1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/linus/gitprojects/dspro2/dspro2/4_modeling/wandb/run-20240620_231957-ifp48yu5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">splendid-sweep-1</a></strong> to <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/azze6syd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5' target=\"_blank\">https://wandb.ai/nlp_ls/dspro2-predicting-temp/runs/ifp48yu5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8r6jm1p1\n",
      "Sweep URL: https://wandb.ai/nlp_ls/dspro2-predicting-temp/sweeps/8r6jm1p1\n",
      "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvae6ird with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: base_augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_identifier: 63289b51067a4c6ede4c44c23a329d82ab4964ed43942794430a9b71ec685b5c\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_size: 81505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdifferent_countries: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_image_size: [1, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmapped_data: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: mobilenet_v2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpredict_coordinates: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"
     ]
    }
   ],
   "source": [
    "model_type = config[\"model_name\"]\n",
    "\n",
    "if predict_coordinates:\n",
    "    project_name = \"predicting-coordinates\"\n",
    "    num_classes = 3\n",
    "elif predict_regions:\n",
    "    project_name = \"predicting-region\"\n",
    "    num_classes = len(region_to_index)\n",
    "else:\n",
    "    num_classes = len(country_to_index)\n",
    "    project_name = \"predicting-country\"\n",
    "\n",
    "evaluator = GeoModelEvaluator(val_dataloader=val_dataloader, num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index, region_to_index=region_to_index, region_index_to_middle_point=region_index_to_middle_point, region_index_to_country_index=region_index_to_country_index, predict_regions=predict_regions if not predict_coordinates else None)\n",
    "\n",
    "# For loading model\n",
    "file_names_to_download = [\".pth\"]\n",
    "# Countries from 81k more mapped dataset, keep in sync with evaluating_models.ipynb\n",
    "countries_only = [\"Albania\", \"Argentina\", \"Australia\", \"Austria\", \"Bangladesh\", \"Belgium\", \"Bolivia, Plurinational State of\", \"Botswana\", \"Brazil\", \"Bulgaria\", \"Cambodia\", \"Canada\", \"Chile\", \"Colombia\", \"Croatia\", \"Czechia\", \"Denmark\", \"Dominican Republic\", \"Ecuador\", \"Estonia\", \"Eswatini\", \"Finland\", \"France\", \"Germany\", \"Ghana\", \"Greece\", \"Guatemala\", \"Hungary\", \"India\", \"Indonesia\", \"Ireland\", \"Israel\", \"Italy\", \"Japan\", \"Kenya\", \"Korea, Republic of\", \"Kyrgyzstan\", \"Lao People's Democratic Republic\", \"Latvia\", \"Lesotho\", \"Lithuania\", \"Malaysia\", \"Malta\", \"Mexico\", \"Montenegro\", \"Netherlands\", \"New Zealand\", \"Nigeria\", \"North Macedonia\", \"Norway\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\", \"Rwanda\", \"Senegal\", \"Serbia\", \"Singapore\", \"Slovakia\", \"Slovenia\", \"South Africa\", \"Spain\", \"Sri Lanka\", \"Sweden\", \"Switzerland\", \"Thailand\", \"T\\u00fcrkiye\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\", \"United States\", \"Uruguay\"]\n",
    "\n",
    "for run_id in run_ids:\n",
    "    with wandb.init(id=run_id, project=f\"dspro2-{project_name}\", entity=\"nlp_ls\", resume=True) as run:\n",
    "        run_info = WandbDownloader.get_run_data(api, entity=\"nlp_ls\", project=project, run=run, download_files=[\"model.pth\", \"model_config.json\"])\n",
    "        # Load the model\n",
    "        evaluator.evaluate(run, model_type=model_type, model_path=run[\"files\"][\"best_model\"], use_balanced_accuracy=True, second_balanced_on_countries_only=countries_only if NUMBER_OF_FILES > 100000 else None, accuracy_per_country=True, median_metric=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Embedding\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from resnet_pytorch import ResNet\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, split_json_and_image_files, load_json_files, load_image_files, load_json_file, load_image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files list from remote\n",
      "Got files list from remote\n",
      "Parsed files list from remote\n",
      "All remote files: 274796\n",
      "All local files: 642825\n",
      "Filtering out unpaired files\n",
      "Filtered out 17666 unpaired files\n",
      "Relevant files: 257130\n",
      "Limited files: 2000\n"
     ]
    }
   ],
   "source": [
    "# set number of files to load\n",
    "NUMBER_OF_FILES = 1000\n",
    "\n",
    "# get list with local data and file paths\n",
    "list_files = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list', file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, from_remote_only=True, download_link='env', limit=NUMBER_OF_FILES, shuffle_seed=43, allow_file_location_env=True, allow_json_file_location_env=True, allow_image_file_location_env=True)\n",
    "\n",
    "json_files, image_files = split_json_and_image_files(list_files)\n",
    "paired_files = list(zip(json_files, image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([128, 3, 50, 50])\n",
      "Coordinates batch shape: torch.Size([128, 2])\n",
      "Country embeddings: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, json_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "        self.transform = transform\n",
    "        self.country_to_index = {}\n",
    "        self.create_country_mapping()\n",
    "        self.embeddings = Embedding(num_embeddings=len(self.country_to_index), embedding_dim=10)  # fixed dimension\n",
    "\n",
    "    def create_country_mapping(self):\n",
    "        unique_countries = set()\n",
    "        for path in self.json_paths:\n",
    "            with open(path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                country = data.get('country_name', 'Unknown')\n",
    "                unique_countries.add(country)\n",
    "        self.country_to_index = {country: idx for idx, country in enumerate(unique_countries)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        with open(self.json_paths[idx], 'r') as file:\n",
    "            data = json.load(file)\n",
    "            country = data.get('country_name', 'Unknown')\n",
    "        \n",
    "        country_index = self.country_to_index[country]\n",
    "        coordinates = torch.tensor(data.get('coordinates', [0, 0]), dtype=torch.float32)\n",
    "        country_embedding = self.embeddings(torch.tensor([country_index]))[0]  # get the first element to match shape\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, coordinates, country_embedding\n",
    "\n",
    "class ImageDataHandler:\n",
    "    def __init__(self, image_paths, json_paths, batch_size=128, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define transformations\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Resize((50, 50)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "        self.transform_test = transforms.Compose([\n",
    "            transforms.Resize((50, 50)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "        # Initialize datasets and loaders\n",
    "        self.train_loader, self.val_loader, self.test_loader = self.create_loaders(train_ratio, val_ratio, test_ratio)\n",
    "\n",
    "    def create_loaders(self, train_ratio, val_ratio, test_ratio):\n",
    "        combined = list(zip(self.image_paths, self.json_paths))\n",
    "        random.shuffle(combined)\n",
    "        total_count = len(combined)\n",
    "        train_end = int(train_ratio * total_count)\n",
    "        val_end = train_end + int(val_ratio * total_count)\n",
    "\n",
    "        train_data = combined[:train_end]\n",
    "        val_data = combined[train_end:val_end]\n",
    "        test_data = combined[val_end:]\n",
    "\n",
    "        # Split lists\n",
    "        train_images, train_jsons = zip(*train_data)\n",
    "        val_images, val_jsons = zip(*val_data)\n",
    "        test_images, test_jsons = zip(*test_data)\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = CustomImageDataset(train_images, train_jsons, self.transform_train)\n",
    "        val_dataset = CustomImageDataset(val_images, val_jsons, self.transform_test)\n",
    "        test_dataset = CustomImageDataset(test_images, test_jsons, self.transform_test)\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "# Creating train, val- and test loaders\n",
    "data_handler = ImageDataHandler(image_files, json_files)\n",
    "train_loader = data_handler.train_loader\n",
    "val_loader = data_handler.val_loader\n",
    "test_loader = data_handler.test_loader\n",
    "\n",
    "# Testloop for the train_loader\n",
    "for images, coordinates, country_embeddings in train_loader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "    print(\"Country embeddings:\", country_embeddings.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First try to predict the coordinates of the image\n",
    "# 2. Then try to predict the country of the image with nodes\n",
    "\n",
    "model = ResNet.from_pretrained('resnet18', num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet50(10).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "            \n",
    "print('Training Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from resnet_pytorch import ResNet\n",
    "import wandb\n",
    "import uuid\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, split_json_and_image_files, load_json_files, load_image_files, load_json_file, load_image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Getting files list from remote\n",
      "Got files list from remote\n",
      "Parsed files list from remote\n",
      "All remote files: 274796\n",
      "All local files: 403361\n",
      "Relevant files: 274796\n",
=======
      "Warning: Skipping all checks\n",
      "All local files: 385695\n",
      "Relevant files: 385695\n",
>>>>>>> Stashed changes
      "Limited files: 20000\n"
     ]
    }
   ],
   "source": [
    "# set number of files to load\n",
    "NUMBER_OF_FILES = 10000\n",
    "# Set to False to use non-mapped data (singleplayer distribution), has more data\n",
    "USE_MAPPED = False\n",
    "\n",
    "USE_MAPPED = True\n",
    "\n",
    "# get list with local data and file paths\n",
    "list_files = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list' if USE_MAPPED else '../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped', file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, from_remote_only=True, download_link='env', limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, allow_image_file_location_env=True)\n",
    "\n",
    "json_files, image_files = split_json_and_image_files(list_files)\n",
    "paired_files = list(zip(json_files, image_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageNameDataset(Dataset):\n",
    "    def __init__(self, image_paths, json_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_paths[idx], self.json_paths[idx]\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((50, 50)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_files) == len(json_files), \"Mismatch in number of images and labels\"\n",
    "\n",
    "file_name_dataset = CustomImageNameDataset(image_files, json_files, transform=transform)\n",
    "file_name_loader = DataLoader(file_name_dataset, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "'/Volumes/LinUSB/combined/geoguessr_location_singleplayer_01DXbeVAxrsJR1Zu_1.png'"
=======
       "'/Users/lukasstoeckli/GitLabProjects/DSPRO2/dspro2/dspro2/.data/geoguessr_location_singleplayer_00AH3Et9ehwdPYL8_0.png'"
>>>>>>> Stashed changes
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_loader.dataset.image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 64\n",
      "Labels: 64\n"
     ]
    }
   ],
   "source": [
    "for temp_image_files, temp_label_files in file_name_loader:\n",
    "    images = load_image_files(temp_image_files)\n",
    "    labels = load_json_files(temp_label_files)\n",
    "    countries = [item['country_name'] for item in labels]\n",
    "    coordinates = [item['coordinates'] for item in labels]\n",
    "    transformed_images = []\n",
    "    for image in images:\n",
    "      transformed_images.append(transform(image))\n",
    "    break  # After the first batch, exit the loop\n",
    "print(\"Images:\", len(images))\n",
    "print(\"Labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, coordinates, countries):\n",
    "        self.images = images\n",
    "        self.coordinates = coordinates\n",
    "        self.countries = countries\n",
    "        self.country_to_index = {country: idx for idx, country in enumerate(set(countries))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        country_index = self.country_to_index[self.countries[idx]]\n",
    "        coordinates = torch.tensor(self.coordinates[idx], dtype=torch.float32)\n",
    "\n",
    "        return image, coordinates, country_index\n",
    "\n",
    "class ImageDataHandler:\n",
    "    def __init__(self, image_paths, json_paths, batch_size=64, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print(len(image_paths))\n",
    "      \n",
    "        file_name_dataset = CustomImageNameDataset(image_paths, json_paths, transform=transform)\n",
    "        file_name_loader = DataLoader(file_name_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        self.images = []\n",
    "        self.countries = []\n",
    "        self.coordinates = []\n",
    "\n",
    "        for batch_image_files, batch_label_files in file_name_loader:\n",
    "            images = load_image_files(batch_image_files)\n",
    "            labels = load_json_files(batch_label_files)\n",
    "            self.countries.extend([item['country_name'] for item in labels])\n",
    "            self.coordinates.extend([item['coordinates'] for item in labels])\n",
    "            for image in images:\n",
    "              self.images.append(transform(image))\n",
    "        \n",
    "        # Initialize datasets and loaders\n",
    "        self.train_loader, self.val_loader, self.test_loader = self.create_loaders(train_ratio, val_ratio, test_ratio)\n",
    "\n",
    "    def create_loaders(self, train_ratio, val_ratio, test_ratio):\n",
    "        assert train_ratio + val_ratio + test_ratio - 1 <= 0.001, \"Ratios should sum to 1\"\n",
    "        \n",
    "        combined = list(zip(self.images, self.coordinates, self.countries))\n",
    "        random.shuffle(combined)\n",
    "        total_count = len(combined)\n",
    "        train_end = int(train_ratio * total_count)\n",
    "        val_end = train_end + int(val_ratio * total_count)\n",
    "\n",
    "        train_data = combined[:train_end]\n",
    "        val_data = combined[train_end:val_end]\n",
    "        test_data = combined[val_end:]\n",
    "        \n",
    "        # Create train, val- and test datasets\n",
    "        train_dataset = CustomImageDataset(*zip(*train_data))\n",
    "        val_dataset = CustomImageDataset(*zip(*val_data))\n",
    "        test_dataset = CustomImageDataset(*zip(*test_data))\n",
    "\n",
    "        # Create train, val- and test dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "10000\n"
=======
      "128293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CustomImageNameDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating Dataloasders with the classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mtrain_loader\n\u001b[1;32m      4\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mval_loader\n",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mImageDataHandler.__init__\u001b[0;34m(self, image_paths, json_paths, batch_size, train_ratio, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcountries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoordinates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 31\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_image_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label_files\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_name_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_image_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_image_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_json_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_label_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "data_handler = ImageDataHandler(image_files, json_files)\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "PRINT_FIRST = True\n",
    "\n",
    "# Print forst batch as an example, to see the structure\n",
    "# 7000 images need 59 sec for processing as information\n",
    "for images, coordinates, country_indices in train_dataloader:\n",
    "    if PRINT_FIRST:\n",
    "      print(\"Images batch shape:\", images.shape)\n",
    "      print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "      print(coordinates[0][0])\n",
    "      print(\"Country indices:\", country_indices.shape)\n",
    "      PRINT_FIRST = False\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model = ResNet.from_pretrained('resnet18', num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set necessary seeds to make notebook reproducible \n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_to_cartesian(coordinates, R=6371):\n",
    "    # Split coordinates to longitude and latitude\n",
    "    lon, lat = coordinates[:, 0], coordinates[:, 1]\n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lon_rad = torch.radians(lon)\n",
    "    lat_rad = torch.radians(lat)\n",
    "\n",
    "    # Cartesian coordinates\n",
    "    x = R * torch.cos(lat_rad) * torch.cos(lon_rad)\n",
    "    y = R * torch.cos(lat_rad) * torch.sin(lon_rad)\n",
    "    z = R * torch.sin(lat_rad)\n",
    "    return torch.stack((x, y, z), dim=1)\n",
    "\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371\n",
    "    return c * r\n",
    "\n",
    "def mean_haversine_distance(preds, targets):\n",
    "    total_distance = 0\n",
    "    total = preds.shape[0]\n",
    "    \n",
    "    for i in range(total):\n",
    "        pred_lon, pred_lat = preds[i, 0], preds[i, 1]\n",
    "        true_lon, true_lat = targets[i, 0], targets[i, 1]\n",
    "        distance = haversine_distance(pred_lon, pred_lat, true_lon, true_lat)\n",
    "        total_distance += distance\n",
    "    \n",
    "    return total_distance / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  with wandb.init(reinit=True) as run:\n",
    "    config = run.config\n",
    "    set_seed(config.seed)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Initializing early stopping\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Rename run name and initialize parameters in model name\n",
    "    model_name = f\"lr_{config.learning_rate}_opt_{config.optimizer}_weightDecay_{config.weight_decay}\"\n",
    "    run_name = model_name + f\"_{uuid.uuid4()}\"\n",
    "    wandb.run.name = run_name\n",
    "    \n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    model = ResNet.from_pretrained('resnet18', num_classes=3).to(device)\n",
    "    # SGD optimizer with different learning rates\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in model.named_parameters() if not n.startswith('fc')], \"lr\": config.learning_rate * 0.1},\n",
    "        {\"params\": model.fc.parameters(), \"lr\": config.learning_rate}\n",
    "    ]\n",
    "\n",
    "    # SGD optimizer\n",
    "    optimizer = optim.AdamW(optimizer_grouped_parameters, weight_decay=config.weight_decay)\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss = 0.0\n",
    "        train_mhd = 0.0 # Mean Haversine Distance for training\n",
    "        model.train()\n",
    "\n",
    "        for images, coordinates, country_indices in train_dataloader:\n",
    "            #print(\"Images shape:\", images.shape)\n",
    "            #print(\"Coordinates shape:\", coordinates.shape)\n",
    "            cartesian_coordinates = coordinates_to_cartesian(coordinates)\n",
    "            images, coordinates = images.to(device), cartesian_coordinates.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            \n",
    "            if output.shape != coordinates.shape:\n",
    "                raise ValueError(\"Mismatch in output and target shapes\")\n",
    "\n",
    "            loss = criterion(output, cartesian_coordinates)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            preds = output.cpu().detach().numpy()\n",
    "            targets = coordinates.cpu().numpy()\n",
    "            train_mhd += mean_haversine_distance(preds, targets) * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        train_mhd /= len(train_dataloader.dataset)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_mhd = 0.0 # Mean Haversine Distance for validation\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, coordinates, country_indices in val_dataloader:\n",
    "                images, coordinates = images.to(device), coordinates.to(device)\n",
    "                output = model(images)\n",
    "                loss = criterion(output, coordinates)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                preds = output.cpu().detach().numpy()\n",
    "                targets = coordinates.cpu().numpy()\n",
    "                val_mhd += mean_haversine_distance(preds, targets) * images.size(0)\n",
    "\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        val_mhd /= len(val_dataloader.dataset)\n",
    "\n",
    "        # Print metrics and log them to wandb\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train MHD: {train_mhd:.4f}, Val Loss: {val_loss:.4f}, Val MHD: {val_mhd:.4f}\")\n",
    "        wandb.log({\n",
    "            \"Train Loss (MSELoss)\": train_loss, \n",
    "            \"Train MHD (Mean Haversine Distance)\": train_mhd, \n",
    "            \"Val Loss (MSELoss)\": val_loss, \n",
    "            \"Val MHD (Mean Haversine Distance)\": val_mhd\n",
    "        })\n",
    "\n",
    "        # Saving model and early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "          best_val_loss = val_loss\n",
    "          torch.save(model.state_dict(), f\"models/resnet18_best_model_checkpoint{model_name}.pth\")\n",
    "          patience_counter = 0 \n",
    "        else:\n",
    "          patience_counter += 1\n",
    "          if patience_counter >= patience:\n",
    "              print(f\"Stopping early after {patience} epochs without improvement\")\n",
    "              break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": f\"dspro2-basemodel-resnet18\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"eval_accuracy\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"values\": [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]},\n",
    "        \"optimizer\": {\"values\": [\"adamW\"]},\n",
    "        \"weight_decay\": {\"values\": [1e-2, 1e-3]},\n",
    "        \"epochs\": {\"values\": [500]},\n",
    "        \"seed\": {\"values\": [42]}\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-basemodel-resnet18\")\n",
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import bottleneck\n",
    "from resnet_pytorch import ResNet\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of processing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 19 files.\n"
     ]
    }
   ],
   "source": [
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#loading labels\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "files = glob.glob(DATA_PATH + \"*.json\")\n",
    "number_of_files = 20\n",
    "\n",
    "labels = []  # Initialize a list to store data from all files\n",
    "\n",
    "if not files:\n",
    "    print(\"No files found. Check the directory path.\")\n",
    "else:\n",
    "    for file_path in files[:number_of_files]:\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                # Load the content of the current file\n",
    "                file_data = json.load(file)\n",
    "                if \"coordinates\" in file_data:\n",
    "                    labels.append(file_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening or reading {file_path}: {e}\")\n",
    "\n",
    "# Output how many files were successfully loaded\n",
    "print(f\"Loaded data from {len(labels)} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'coordinates': [51.08673095703125, 3.8212528228759766]},\n",
       " {'coordinates': [38.69101333618164, 22.3980770111084]},\n",
       " {'coordinates': [48.94839096069336, -55.669677734375]},\n",
       " {'coordinates': [45.62511444091797, -79.88330841064453]},\n",
       " {'coordinates': [55.164520263671875, 61.39071273803711]},\n",
       " {'coordinates': [48.70686340332031, 2.33329176902771]},\n",
       " {'coordinates': [57.00322341918945, 8.783960342407227]},\n",
       " {'coordinates': [56.090667724609375, 37.55679702758789]},\n",
       " {'coordinates': [17.896394729614258, 102.7203598022461]},\n",
       " {'coordinates': [56.845924377441406, 60.62533187866211]},\n",
       " {'coordinates': [64.14692687988281, -21.88874053955078]},\n",
       " {'coordinates': [8.691835403442383, 80.51228332519531]},\n",
       " {'coordinates': [-30.146350860595703, -51.12898635864258]},\n",
       " {'coordinates': [50.983604431152344, -114.00588989257812]},\n",
       " {'coordinates': [40.71820831298828, -73.95831298828125]},\n",
       " {'coordinates': [56.130924224853516, 47.227935791015625]},\n",
       " {'coordinates': [-37.798309326171875, 145.2571258544922]},\n",
       " {'coordinates': [33.30577087402344, -96.03694152832031]},\n",
       " {'coordinates': [-8.021086692810059, -78.14344787597656]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51.08673095703125, 3.8212528228759766]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just load the first image, avoid Multiplayer\n",
    "labels[0][\"coordinates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of processing input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 image files.\n"
     ]
    }
   ],
   "source": [
    "# loading images\n",
    "files = glob.glob(DATA_PATH + \"*.png\")\n",
    "\n",
    "if not files:\n",
    "    print(\"No files found. Check the directory path.\")\n",
    "else:\n",
    "    images = [] \n",
    "    for file_path in files[:number_of_files]:\n",
    "        try:\n",
    "            # channels, height, width is the pytorch convention\n",
    "            with Image.open(file_path) as img:\n",
    "                img_array = np.array(img)\n",
    "                img_array = img_array.transpose((2, 0, 1))\n",
    "                #images.append(img_array)\n",
    "                images.append(file_path)\n",
    "        except IOError as e:\n",
    "            print(f\"Error opening or reading {file_path}: {e}\")\n",
    "\n",
    "# Output how many files were successfully processed\n",
    "print(f\"Processed {len(images)} image files.\")\n",
    "#display(Image.open(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size (height, width): 180x320\n",
      "Image array shape: (180, 320, 4)\n",
      "Image mode: RGBA\n",
      "Image format: PNG\n"
     ]
    }
   ],
   "source": [
    "# Inside the loop, convert the image to a numpy array and store it\n",
    "with Image.open(file_path) as img:\n",
    "    width, height = img.size\n",
    "    img_array = np.array(img)\n",
    "    print(f\"Image size (height, width): {height}x{width}\")\n",
    "    print(f\"Image array shape: {img_array.shape}\")\n",
    "    print(f\"Image mode: {img.mode}\")\n",
    "    print(f\"Image format: {img.format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_location_singleplayer_rm8goISVT6SLjGR9_4_resized.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#images[0].shape\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class of creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split before to train, validation, and test\n",
    "dataset = CustomImageDataset(images, labels, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x16ddd7bf0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files list from remote\n",
      "Got files list from remote\n",
      "Parsed files list from remote\n",
      "All remote files: 274796\n",
      "Filtering out unpaired files\n",
      "Filtered out 17666 unpaired files\n",
      "Relevant files: 257130\n",
      "Limited files: 200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load\n",
    "\n",
    "# loading local data\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "if not DATA_PATH:\n",
    "    raise ValueError(\"DATA_PATH environment variable is not set\")\n",
    "\n",
    "files = glob.glob(DATA_PATH + \"*.json\")\n",
    "\n",
    "# get list with local data and file paths\n",
    "list = get_data_to_load(loading_file='./data_list', file_location=DATA_PATH, image_file_location=DATA_PATH, allow_new_file_creation=True, from_remote_only=True, download_link='env', limit=100, shuffle_seed=43)\n",
    "\n",
    "# List of data to load\n",
    "print(len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = [item for item in list if item.endswith(\".png\")]\n",
    "labels = [item for item in list if item.endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_location_singleplayer_3jd33hbXzAHBrYDj_4.png'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files list from remote\n",
      "Got files list from remote\n",
      "Parsed files list from remote\n",
      "All remote files: 274796\n",
      "Filtering out unpaired files\n",
      "Filtered out 17666 unpaired files\n",
      "Relevant files: 257130\n",
      "Limited files: 20\n",
      "Some files are missing: ['../.data/geoguessr_location_singleplayer_2V749xmsAtz2islo_2.png', '../.data/geoguessr_location_singleplayer_TH7jVALVRMmGsPdr_1.png', '../.data/geoguessr_location_singleplayer_I5yMnDSVlaGLEa12_1.png', '../.data/geoguessr_location_singleplayer_NLPqsR0Hd0a0qQp8_0.png', '../.data/geoguessr_location_singleplayer_hszkmUG9P9AhshF0_3.png', '../.data/geoguessr_location_singleplayer_yfDqCnA3F4irzZ99_0.png', '../.data/geoguessr_location_singleplayer_hk06fSN25XgNQ58S_3.png', '../.data/geoguessr_location_singleplayer_gDZBXUA5tdrGkN8q_0.png', '../.data/geoguessr_location_singleplayer_91rU5yOIkTwHiYtQ_0.png', '../.data/geoguessr_location_singleplayer_lys6kNZhPdxRYUXU_4.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding your custom data loading script's path to the system path\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load\n",
    "\n",
    "# Assume DATA_PATH is set properly\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "if not DATA_PATH:\n",
    "    raise ValueError(\"DATA_PATH environment variable is not set\")\n",
    "\n",
    "# Get all JSON files in the directory\n",
    "json_files = glob.glob(os.path.join(DATA_PATH, \"*.json\"))\n",
    "# Assuming corresponding PNG files should exist\n",
    "png_files = [f.replace('.json', '.png') for f in json_files]\n",
    "\n",
    "# Get list with local data and file paths from your custom loader\n",
    "loaded_files = get_data_to_load(loading_file='./data_list', file_location=DATA_PATH, image_file_location=DATA_PATH, allow_new_file_creation=True, from_remote_only=True, download_link='env', limit=10, shuffle_seed=43)\n",
    "\n",
    "# Checking the existence of each file in the loaded list\n",
    "missing_files = [f for f in loaded_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print(f\"Some files are missing: {missing_files}\")\n",
    "else:\n",
    "    print(\"All files from the loaded list exist in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_result_singleplayer_p2oxCfgo7krY3o3k_3.png'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â path from the \"combined\" data set from yutaro\n",
    "png_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_location_singleplayer_3jd33hbXzAHBrYDj_4.png'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path from the data_loader with the cleaned images\n",
    "input_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../.data/geoguessr_location_singleplayer_Nj7x19xz68DjgyJK_4.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m      2\u001b[0m   img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[1;32m      3\u001b[0m   img_array \u001b[38;5;241m=\u001b[39m img_array\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../.data/geoguessr_location_singleplayer_Nj7x19xz68DjgyJK_4.png'"
     ]
    }
   ],
   "source": [
    "# example of loading data for input images\n",
    "with Image.open(input_images[40]) as img:\n",
    "  img_array = np.array(img)\n",
    "  img_array = img_array.transpose((2, 0, 1))\n",
    "  #images.append(img_array)\n",
    "  images.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.19734001159668, 120.5780029296875]\n"
     ]
    }
   ],
   "source": [
    "# example of loading data for labels\n",
    "with open(labels[0], 'r') as file:\n",
    "      file_data = json.load(file)\n",
    "      label = file_data['coordinates'] if 'coordinates' in file_data else None\n",
    "      print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_result_singleplayer_3jd33hbXzAHBrYDj_4.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, json_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load labels from JSON file\n",
    "        json_path = self.json_paths[idx]\n",
    "        with open(json_path, 'r') as file:\n",
    "            file_data = json.load(file)\n",
    "            label = file_data['coordinates'] if 'coordinates' in file_data else None\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = [item for item in list if item.endswith('.png')]\n",
    "labels = [item for item in list if item.endswith('.json')]\n",
    "\n",
    "assert len(input_images) == len(labels), \"Mismatch in number of images and labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_result_singleplayer_VROl268f9c1R4jWy_0.json'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.__getitem__(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(input_images, labels, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../.data/geoguessr_location_singleplayer_3jd33hbXzAHBrYDj_4.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader\n",
    "dataset = CustomImageDataset(input_images, labels, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../.data/geoguessr_location_singleplayer_NVY1TBOqwZCElNOL_2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImages batch shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabels batch shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[0;32m---> 21\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     23\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/GitLabProjects/DSPRO2/dspro2/.venv/lib/python3.12/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../.data/geoguessr_location_singleplayer_NVY1TBOqwZCElNOL_2.png'"
     ]
    }
   ],
   "source": [
    "for images, labels in loader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    break  # After printing the first batch, exit the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload images and labels into tensors\n",
    "images = []\n",
    "labels_data = []\n",
    "\n",
    "for img_path, json_path in zip(input_images, labels):\n",
    "    # Load and transform the image\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    images.append(image)\n",
    "\n",
    "    # Load and process the JSON file for labels\n",
    "    with open(json_path, 'r') as file:\n",
    "        file_data = json.load(file)\n",
    "        label = file_data['coordinates'] if 'coordinates' in file_data else [0, 0]  # Default to [0,0] if no coordinates\n",
    "        labels_data.append(torch.tensor(label, dtype=torch.float32))\n",
    "\n",
    "# Create dataset from preloaded data\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Initialize dataset and DataLoader\n",
    "dataset = CustomImageDataset(images, labels_data)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the DataLoader\n",
    "for images, labels in loader:\n",
    "    print(images.shape, labels)\n",
    "    break  # Break after printing first batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (list of torch.Tensor): List of images as tensors.\n",
    "            labels (list): List of labels.\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve image and label already in the correct format\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load images\n",
    "image_paths = glob.glob('../../1_data_collection/.data/*.png')\n",
    "images = []\n",
    "for img_path in image_paths:\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    images.append(image)\n",
    "\n",
    "# Assume labels are loaded and processed into a corresponding list `labels`\n",
    "labels = [...]  # This should match the length and order of `images`\n",
    "\n",
    "# Create dataset\n",
    "dataset = CustomImageDataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "# Path where the JSON files are stored\n",
    "json_path = '../../1_data_collection/.data/*.json'\n",
    "files = glob.glob(json_path)\n",
    "number_of_files = 20  # Limit the number of files to process\n",
    "\n",
    "labels = []  # Initialize a list to store labels from the files\n",
    "\n",
    "if not files:\n",
    "    print(\"No files found. Check the directory path.\")\n",
    "else:\n",
    "    for file_path in files[:number_of_files]:\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                # Load the content of the current file\n",
    "                file_data = json.load(file)\n",
    "                # Check if 'coordinates' key exists\n",
    "                if \"coordinates\" in file_data:\n",
    "                    # Append the coordinates or the whole data, depending on need\n",
    "                    labels.append(file_data['coordinates'])\n",
    "                else:\n",
    "                    # Handle cases where 'coordinates' might not exist\n",
    "                    labels.append(None)  # Or some default value, e.g., {}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening or reading {file_path}: {e}\")\n",
    "\n",
    "# Output how many files were successfully loaded with labels\n",
    "print(f\"Loaded labels from {len(labels)} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "data = {}\n",
    "data[\"input\"] = labels\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.20\n",
    "test_ratio = 0.10\n",
    "\n",
    "# Shuffle data randomly\n",
    "random.shuffle(data[\"input\"])\n",
    "\n",
    "# Calculate split indices\n",
    "total_images = len(data[\"input\"])\n",
    "train_end = int(train_ratio * total_images)\n",
    "val_end = train_end + int(val_ratio * total_images)\n",
    "\n",
    "# Split the data\n",
    "train_data = data[\"input\"][:train_end]\n",
    "val_data = data[\"input\"][train_end:val_end]\n",
    "test_data = data[\"input\"][val_end:]\n",
    "\n",
    "print(f\"Train set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataet and crearting, split before!!!\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_data,\n",
    "    \"validation\": val_data,\n",
    "    \"test\": test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=128,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet.from_pretrained('resnet18', num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet50(10).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "            \n",
    "print('Training Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

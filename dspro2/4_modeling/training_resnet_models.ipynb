{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important for gpuhub\n",
    "# !pip install -r ../../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "from geo_model_trainer import GeoModelTrainer\n",
    "from image_data_handler import ImageDataHandler\n",
    "\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, split_json_and_image_files, hash_filenames\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.getenv('WANDB_TOKEN')\n",
    "# Define where to run\n",
    "env_path = '../../.env'\n",
    "if not WANDB_TOKEN and os.path.exists(env_path):\n",
    "  load_dotenv(env_path)\n",
    "  WANDB_TOKEN = os.getenv('WANDB_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Print the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Print the total and available memory\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1e9  # Convert bytes to GB\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "    # Print other properties\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"CUDA Capability: {device_properties.major}.{device_properties.minor}\")\n",
    "    print(f\"Multi-Processor Count: {device_properties.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files list from remote\n",
      "Got files list from remote\n",
      "Parsed files list from remote\n",
      "All remote files: 705681\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Volumes/LinUSB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m USE_MAPPED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# get list with local data and file paths\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m list_files \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_to_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloading_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../3_data_preparation/04_data_cleaning/updated_data_list_more\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mUSE_MAPPED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfile_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../3_data_preparation/01_enriching/.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_file_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../1_data_collection/.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_new_file_creation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfrom_remote_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMBER_OF_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_file_location_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_json_file_location_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mallow_image_file_location_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_download_link_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(list_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m json_files, image_files \u001b[38;5;241m=\u001b[39m split_json_and_image_files(list_files)\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../data_loader.py:607\u001b[0m, in \u001b[0;36mget_data_to_load\u001b[0;34m(loading_file, file_location, json_file_location, image_file_location, filter_text, type, limit, allow_new_file_creation, countries_map, countries_map_percentage_threshold, countries_map_slack_factor, allow_missing_in_map, passthrough_map, shuffle_seed, download_link, pre_download, from_remote_only, allow_file_location_env, allow_json_file_location_env, allow_image_file_location_env, allow_download_link_env, num_download_connections, allow_num_download_connections_env, countries_map_cached_basenames_to_countries, return_basenames_too)\u001b[0m\n\u001b[1;32m    603\u001b[0m   download_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    605\u001b[0m pre_download \u001b[38;5;241m=\u001b[39m pre_download \u001b[38;5;129;01mor\u001b[39;00m countries_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 607\u001b[0m basenames, basenames_to_locations_map, downloadable_files \u001b[38;5;241m=\u001b[39m \u001b[43m_get_files_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_file_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_remote_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_new_file_creation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_checks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_download_connections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_download_connections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_files_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_files_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m has_loading_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    610\u001b[0m files_from_loading_file \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../data_loader.py:524\u001b[0m, in \u001b[0;36m_get_files_list\u001b[0;34m(file_location, json_file_location, image_file_location, filter_text, type, download_link, pre_download, from_remote_only, dedupe_and_remove_unpaired, skip_checks, num_download_connections, use_files_list, nested)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m from_remote_only:\n\u001b[1;32m    523\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo download link given\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m local_files, basenames_to_locations_map \u001b[38;5;241m=\u001b[39m \u001b[43m_get_list_from_local_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_file_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasenames_to_locations_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_files_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_files_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m from_remote_only:  \n\u001b[1;32m    526\u001b[0m   basenames\u001b[38;5;241m.\u001b[39mextend(local_files)\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../data_loader.py:487\u001b[0m, in \u001b[0;36m_get_list_from_local_dir\u001b[0;34m(file_location, json_file_location, image_file_location, filter_text, type, basenames_to_locations_map, use_files_list, nested)\u001b[0m\n\u001b[1;32m    485\u001b[0m all_files \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m   all_files\u001b[38;5;241m.\u001b[39mextend(\u001b[43mget_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_files_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_files_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json_file_location \u001b[38;5;241m!=\u001b[39m file_location \u001b[38;5;129;01mand\u001b[39;00m json_file_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    489\u001b[0m   all_files\u001b[38;5;241m.\u001b[39mextend(get_json_files(json_file_location, use_files_list\u001b[38;5;241m=\u001b[39muse_files_list, nested\u001b[38;5;241m=\u001b[39mnested))\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../data_loader.py:473\u001b[0m, in \u001b[0;36mget_files\u001b[0;34m(path, use_files_list, nested)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_files\u001b[39m(path, use_files_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 473\u001b[0m   files \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_files_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_files_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/gitprojects/dspro2/dspro2/4_modeling/../data_loader.py:448\u001b[0m, in \u001b[0;36mget_all_files\u001b[0;34m(path, use_files_list, nested)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_files\u001b[39m(path, use_files_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    446\u001b[0m   \u001b[38;5;66;03m# create the directory if it does not exist\u001b[39;00m\n\u001b[1;32m    447\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m--> 448\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m   stripped_path \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, path)\n\u001b[1;32m    451\u001b[0m   \u001b[38;5;66;03m# make absolute\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Volumes/LinUSB'"
     ]
    }
   ],
   "source": [
    "# set number of files to load\n",
    "NUMBER_OF_FILES = 0 # 100000\n",
    "# Set to False to use non-mapped data (singleplayer distribution), has more data\n",
    "USE_MAPPED = True\n",
    "\n",
    "# get list with local data and file paths\n",
    "list_files = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list_more' if USE_MAPPED else '../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped', \n",
    "                              file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, \n",
    "                              from_remote_only=True, download_link='default', limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, \n",
    "                              allow_image_file_location_env=True, allow_download_link_env=True)\n",
    "\n",
    "json_files, image_files = split_json_and_image_files(list_files)\n",
    "paired_files = list(zip(json_files, image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted image found and skipped: /home/jovyan/dspro2/dspro2/.data/geoguessr_location_singleplayer_FjbsHTUCjCEjccK3_3.png\n",
      "Total non-corrupted pairs: 74999\n"
     ]
    }
   ],
   "source": [
    "def filter_corrupted_pairs(paired_files):\n",
    "    non_corrupted_pairs = []\n",
    "    \n",
    "    for json_path, image_path in paired_files:\n",
    "      non_corrupted_pairs.append((json_path, image_path))\n",
    "      \n",
    "    return non_corrupted_pairs\n",
    "\n",
    "# Filter the paired_files list to remove any corrupted entries\n",
    "filtered_paired_files = filter_corrupted_pairs(paired_files)\n",
    "print(f\"Total non-corrupted pairs: {len(filtered_paired_files)}\")\n",
    "\n",
    "def split_json_and_image_files(paired_files):\n",
    "    json_files = [json_file for json_file, _ in paired_files if json_file.endswith('.json')]\n",
    "    image_files = [image_file for _, image_file in paired_files if image_file.endswith('.png')]\n",
    "    return json_files, image_files\n",
    "\n",
    "json_files, image_files = split_json_and_image_files(filtered_paired_files)\n",
    "paired_files = filtered_paired_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74999, 74999, 74999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files), len(image_files), len(paired_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default was 50, 50\n",
    "data_augmentation = \"base_augmentation\"\n",
    "image_size = [80, 130]\n",
    "# Original size is  pixelHeight: 180, pixelWidth: 320\n",
    "#image_size = [180, 320]\n",
    "\n",
    "if data_augmentation == \"base_augmentation\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size[0], image_size[1])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "elif data_augmentation == \"full_augmentation\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size[0], image_size[1])),\n",
    "        transforms.RandomRotation(10),          # Randomly rotate the image by up to 10 degrees\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),  # Randomly change brightness (lower limit to simulate night, upper limit for bright daylight)\n",
    "            contrast=(0.5, 1.5),    # Randomly change contrast\n",
    "            saturation=(0.5, 1.5),  # Randomly change saturation\n",
    "            hue=(-0.1, 0.1)         # Randomly change hue\n",
    "        ),\n",
    "        transforms.ToTensor(),                  # Convert the image to a tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalize the image\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and labels:   0%|          | 17/15000 [04:03<59:39:42, 14.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating Dataloasders with the classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMBER_OF_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mtrain_loader\n\u001b[1;32m      4\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mval_loader\n",
      "File \u001b[0;32m~/dspro2/dspro2/4_modeling/image_data_handler.py:35\u001b[0m, in \u001b[0;36mImageDataHandler.__init__\u001b[0;34m(self, image_paths, json_paths, transform, datasize, batch_size, train_ratio, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#self.coordinates.extend([item.get('coordinates', 'Unknown') for item in labels])\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m#self.images.append(transform(image).to(device))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Initialize datasets and loaders\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_loaders(train_ratio, val_ratio, test_ratio)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/transforms/functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "\n",
    "# Hash the files list to get a unique identifier for the data\n",
    "hash_filenames = hash_filenames(list_files)\n",
    "\n",
    "data_handler = ImageDataHandler(image_files, json_files, transform, NUMBER_OF_FILES, batch_size=100)\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader\n",
    "country_to_index = data_handler.country_to_index\n",
    "\n",
    "# Load the country_to_index mapping and print the count of different countries\n",
    "print(\"Dataset size:\", NUMBER_OF_FILES)\n",
    "print(\"Dataset identifier:\", hash_filenames)\n",
    "print(f\"Count of different countries: {len(country_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "PRINT_FIRST = True\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices in train_dataloader:\n",
    "    if PRINT_FIRST:\n",
    "      print(\"Images batch shape:\", images.shape)\n",
    "      print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "      print(coordinates[0])\n",
    "      print(\"Country indices:\", country_indices.shape)\n",
    "      print(country_indices[0])\n",
    "      PRINT_FIRST = False\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Load the pre-trained ResNet50 model with updated approach\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Change the output features of the last layer to 2 for binary classification\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Initialize the new last layer with random weights\n",
    "nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "nn.init.constant_(model.fc.bias, 0)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_types = [\"resnet18\", \"resnet50\"]\n",
    "model_types = [\"mobilenet_v2\"]\n",
    "predict_coordinates=False\n",
    "wandb.login(key=WANDB_TOKEN) if WANDB_TOKEN else wandb.login()\n",
    "\n",
    "for model_type in model_types:\n",
    "    if predict_coordinates:\n",
    "        project_name = \"predicting-coordinates\"\n",
    "        num_classes = 2\n",
    "        sweep_goal = \"minimize\"\n",
    "        sweep_metric_name = \"Validation Distance (km)\"\n",
    "    else:\n",
    "        num_classes = len(country_to_index)\n",
    "        project_name = \"predicting-country\"\n",
    "        sweep_goal = \"maximize\"\n",
    "        sweep_metric_name = \"Validation Accuracy Top 1\"\n",
    "    \n",
    "    sweep_config = {\n",
    "        \"name\": f\"dspro2-basemodel-{model_type}-datasize-{NUMBER_OF_FILES}-input_imagesize-{image_size[0]}x{image_size[1]}\",\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": sweep_goal, \"name\": sweep_metric_name},\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\"values\": [1e-2, 1e-3, 1e-4]},\n",
    "            \"optimizer\": {\"values\": [\"adamW\"]},\n",
    "            \"weight_decay\": {\"values\": [1e-3]},\n",
    "            \"epochs\": {\"values\": [100]},\n",
    "            \"dataset_size\": {\"values\": [NUMBER_OF_FILES]},\n",
    "            \"dataset_identifier\": {\"values\": [hash_filenames]},\n",
    "            \"seed\": {\"values\": [42]},\n",
    "            \"model_name\": {\"values\": [model_type]},\n",
    "            \"input_image_size\": {\"values\": [image_size]},\n",
    "            \"predict_coordinates\": {\"values\": [predict_coordinates]},\n",
    "            \"mapped_data\": {\"values\": [USE_MAPPED]},\n",
    "            \"different_countries\": {\"values\": [len(country_to_index)]},\n",
    "            \"data_augmentation\": {\"values\": [data_augmentation]}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-basemodel-{project_name}\")\n",
    "    trainer = GeoModelTrainer(datasize=NUMBER_OF_FILES, train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                              num_classes=num_classes, predict_coordinates=predict_coordinates, country_to_index=country_to_index if not predict_coordinates else None)\n",
    "\n",
    "    wandb.agent(sweep_id, function=trainer.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

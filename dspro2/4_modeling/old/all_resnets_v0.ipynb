{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from resnet_pytorch import ResNet\n",
    "import wandb\n",
    "import uuid\n",
    "\n",
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from data_loader import get_data_to_load, split_json_and_image_files, load_json_files, load_image_files, load_json_file, load_image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_json_files(directory):\n",
    "    json_file_count = 0\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            json_file_count += 1\n",
    "\n",
    "    return json_file_count\n",
    "\n",
    "# Path to the directory\n",
    "folder_path = \"/home/jovyan/dspro2/dspro2/.data\"\n",
    "\n",
    "# Count JSON files in the specified directory\n",
    "count = count_json_files(folder_path)\n",
    "print(f\"Total JSON files in the directory: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of files to load\n",
    "NUMBER_OF_FILES = 10000\n",
    "# Set to False to use non-mapped data (singleplayer distribution), has more data\n",
    "USE_MAPPED = False\n",
    "\n",
    "# get list with local data and file paths\n",
    "list_files = get_data_to_load(loading_file='../3_data_preparation/04_data_cleaning/updated_data_list' if USE_MAPPED else '../3_data_preparation/04_data_cleaning/updated_data_list_non_mapped', \n",
    "                              file_location='../3_data_preparation/01_enriching/.data', image_file_location='../1_data_collection/.data', allow_new_file_creation=False, \n",
    "                              from_remote_only=True, download_link='default', limit=NUMBER_OF_FILES, shuffle_seed=42, allow_file_location_env=True, allow_json_file_location_env=True, \n",
    "                              allow_image_file_location_env=True, allow_download_link_env=True)\n",
    "\n",
    "json_files, image_files = split_json_and_image_files(list_files)\n",
    "paired_files = list(zip(json_files, image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_count = 0\n",
    "country_names_count = 0\n",
    "for path in json_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        if not data.get(\"coordinates\"):\n",
    "            #print(data)\n",
    "            coordinates_count += 1\n",
    "        if not data.get(\"country_name\"):\n",
    "            #print(data)\n",
    "            country_names_count += 1\n",
    "print(f\"Missing Files with no coordinates : {coordinates_count}\")\n",
    "print(f\"Missing Files with no country name : {country_names_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corrupted_pairs(paired_files):\n",
    "    non_corrupted_pairs = []\n",
    "    \n",
    "    for json_path, image_path in paired_files:\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                img.verify()  # verify that it's a readable image\n",
    "            non_corrupted_pairs.append((json_path, image_path))\n",
    "        except (IOError, OSError):\n",
    "            print(f\"Corrupted image found and skipped: {image_path}\")\n",
    "\n",
    "    return non_corrupted_pairs\n",
    "\n",
    "# Filter the paired_files list to remove any corrupted entries\n",
    "filtered_paired_files = filter_corrupted_pairs(paired_files)\n",
    "print(f\"Total non-corrupted pairs: {len(filtered_paired_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_json_and_image_files(paired_files):\n",
    "    json_files = [json_file for json_file, _ in paired_files if json_file.endswith('.json')]\n",
    "    image_files = [image_file for _, image_file in paired_files if image_file.endswith('.png')]  # Assuming all images are .png\n",
    "    return json_files, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files, image_files = split_json_and_image_files(filtered_paired_files)\n",
    "paired_files = filtered_paired_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_files), len(image_files), len(paired_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageNameDataset(Dataset):\n",
    "    def __init__(self, image_paths, json_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.json_paths = json_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_paths[idx], self.json_paths[idx]\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((50, 50)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_files) == len(json_files), \"Mismatch in number of images and labels\"\n",
    "\n",
    "file_name_dataset = CustomImageNameDataset(image_files, json_files, transform=transform)\n",
    "file_name_loader = DataLoader(file_name_dataset, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_loader.dataset.image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_image_files, temp_label_files in file_name_loader:\n",
    "    images = load_image_files(temp_image_files)\n",
    "    labels = load_json_files(temp_label_files)\n",
    "    countries = [item['country_name'] for item in labels]\n",
    "    coordinates = [item['coordinates'] for item in labels]\n",
    "    transformed_images = []\n",
    "    for image in images:\n",
    "      transformed_images.append(transform(image))\n",
    "    break  # After the first batch, exit the loop\n",
    "print(\"Images:\", len(images))\n",
    "print(\"Labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, coordinates, countries):\n",
    "        self.images = images\n",
    "        self.coordinates = coordinates\n",
    "        self.countries = countries\n",
    "        self.country_to_index = {country: idx for idx, country in enumerate(set(countries))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        country_index = self.country_to_index[self.countries[idx]]\n",
    "        coordinates = torch.tensor(self.coordinates[idx], dtype=torch.float32)\n",
    "\n",
    "        return image, coordinates, country_index\n",
    "\n",
    "class ImageDataHandler:\n",
    "    def __init__(self, image_paths, json_paths, batch_size=128, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print(len(image_paths))\n",
    "      \n",
    "        file_name_dataset = CustomImageNameDataset(image_paths, json_paths, transform=transform)\n",
    "        file_name_loader = DataLoader(file_name_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        self.images = []\n",
    "        self.countries = []\n",
    "        self.coordinates = []\n",
    "\n",
    "        for batch_image_files, batch_label_files in file_name_loader:\n",
    "            images = load_image_files(batch_image_files)\n",
    "            labels = load_json_files(batch_label_files)\n",
    "            for item in labels:\n",
    "                if not 'country_name' in item:\n",
    "                    print(item)\n",
    "            #self.countries.append(item['country_name'])\n",
    "            self.countries.extend([item.get('country_name', 'Unknown') for item in labels])\n",
    "            #self.coordinates.extend([item['coordinates'] for item in labels])\n",
    "            self.coordinates.extend([item.get('coordinates', 'Unknown') for item in labels])\n",
    "            for image in images:\n",
    "              self.images.append(transform(image))\n",
    "        \n",
    "        # Initialize datasets and loaders\n",
    "        self.train_loader, self.val_loader, self.test_loader = self.create_loaders(train_ratio, val_ratio, test_ratio)\n",
    "\n",
    "    def create_loaders(self, train_ratio, val_ratio, test_ratio):\n",
    "        assert train_ratio + val_ratio + test_ratio - 1 <= 0.001, \"Ratios should sum to 1\"\n",
    "        \n",
    "        combined = list(zip(self.images, self.coordinates, self.countries))\n",
    "        random.shuffle(combined)\n",
    "        total_count = len(combined)\n",
    "        train_end = int(train_ratio * total_count)\n",
    "        val_end = train_end + int(val_ratio * total_count)\n",
    "\n",
    "        train_data = combined[:train_end]\n",
    "        val_data = combined[train_end:val_end]\n",
    "        test_data = combined[val_end:]\n",
    "        \n",
    "        # Create train, val- and test datasets\n",
    "        train_dataset = CustomImageDataset(*zip(*train_data))\n",
    "        val_dataset = CustomImageDataset(*zip(*val_data))\n",
    "        test_dataset = CustomImageDataset(*zip(*test_data))\n",
    "\n",
    "        # Create train, val- and test dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataloasders with the classes\n",
    "data_handler = ImageDataHandler(image_files, json_files)\n",
    "train_dataloader = data_handler.train_loader\n",
    "val_dataloader = data_handler.val_loader\n",
    "test_dataloader = data_handler.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train batches:\", len(train_dataloader.dataset), \"\")\n",
    "\n",
    "PRINT_FIRST = True\n",
    "\n",
    "# Print first batch as an example, to see the structure\n",
    "for images, coordinates, country_indices in train_dataloader:\n",
    "    if PRINT_FIRST:\n",
    "      print(\"Images batch shape:\", images.shape)\n",
    "      print(\"Coordinates batch shape:\", coordinates.shape)\n",
    "      print(coordinates[0])\n",
    "      print(\"Country indices:\", country_indices.shape)\n",
    "      PRINT_FIRST = False\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet50 model with updated approach\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Change the output features of the last layer to 2 for binary classification\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Initialize the new last layer with random weights\n",
    "nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "nn.init.constant_(model.fc.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_resnet(model_type='resnet50'):\n",
    "    if model_type == 'resnet18':\n",
    "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    elif model_type == 'resnet34':\n",
    "        model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "    elif model_type == 'resnet50':\n",
    "        model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    elif model_type == 'resnet101':\n",
    "        model = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "    elif model_type == 'resnet152':\n",
    "        model = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Supported types are: resnet18, resnet34, resnet50, resnet101, resnet152.\")\n",
    "\n",
    "    # Print the current last layer\n",
    "    print(f\"Original last layer of {model_type}:\", model.fc)\n",
    "    \n",
    "    # Re-initialize the last layer with random weights\n",
    "    model.fc = nn.Linear(model.fc.in_features, model.fc.out_features)\n",
    "    nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "    nn.init.constant_(model.fc.bias, 0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model = initialize_resnet('resnet18')\n",
    "resnet18_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = initialize_resnet('resnet50')\n",
    "resnet50_model.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set necessary seeds to make notebook reproducible \n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_to_cartesian(lon, lat, R=6371):\n",
    "    # Convert degrees to radians\n",
    "    lon_rad = np.radians(lon)\n",
    "    lat_rad = np.radians(lat)\n",
    "\n",
    "    # Cartesian coordinates using numpy\n",
    "    x = R * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = R * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = R * np.sin(lat_rad)\n",
    "    return np.stack([x, y, z], axis=-1)  # ensure the output is a numpy array with the correct shape\n",
    "\n",
    "def spherical_distance(cartesian1, cartesian2, R=6371.0):\n",
    "    cartesian1 = cartesian1.to(cartesian2.device)\n",
    "    dot_product = (cartesian1 * cartesian2).sum(dim=1)\n",
    "    \n",
    "    norms1 = cartesian1.norm(p=2, dim=1)\n",
    "    norms2 = cartesian2.norm(p=2, dim=1)\n",
    "\n",
    "    cos_theta = dot_product / (norms1 * norms2)\n",
    "    cos_theta = torch.clamp(cos_theta, -1.0, 1.0)\n",
    "    \n",
    "    theta = torch.acos(cos_theta)\n",
    "    # curved distance -> \"Bogenmass\"\n",
    "    distance = R * theta\n",
    "    return distance\n",
    "\n",
    "def mean_spherical_distance(preds, targets):\n",
    "    distances = spherical_distance(preds, targets)\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoModelTrainer:\n",
    "    def __init__(self, model_type='resnet50', num_classes=2, use_coordinates=True):\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.use_coordinates = use_coordinates\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = self.initialize_model().to(self.device)\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        if self.model_type == 'resnet18':\n",
    "            model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        elif self.model_type == 'resnet34':\n",
    "            model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        elif self.model_type == 'resnet50':\n",
    "            model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        elif self.model_type == 'resnet101':\n",
    "            model = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "        elif self.model_type == 'resnet152':\n",
    "            model = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type. Supported types are: resnet18, resnet34, resnet50, resnet101, resnet152.\")\n",
    "        \n",
    "        # Modify the final layer based on the number of classes\n",
    "        model.fc = nn.Linear(model.fc.in_features, self.num_classes)\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        with wandb.init(reinit=True) as run:\n",
    "            config = run.config\n",
    "            set_seed(config.seed)\n",
    "            \n",
    "            # Set seeds, configure optimizers, losses, etc.\n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            patience = 100\n",
    "\n",
    "            # Rename run name and initialize parameters in model name\n",
    "            model_name = f\"model_{config.model_name}_lr_{config.learning_rate}_opt_{config.optimizer}_weightDecay_{config.weight_decay}\"\n",
    "            run_name = model_name + f\"_{uuid.uuid4()}\"\n",
    "            wandb.run.name = run_name\n",
    "            \n",
    "            # Configure the optimizer\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\"params\": [p for n, p in self.model.named_parameters() if not n.startswith('fc')], \"lr\": config.learning_rate * 0.1},\n",
    "                {\"params\": self.model.fc.parameters(), \"lr\": config.learning_rate}\n",
    "            ]\n",
    "            optimizer = optim.AdamW(optimizer_grouped_parameters, weight_decay=config.weight_decay)\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            for epoch in range(config.epochs):\n",
    "                train_loss, train_distance = self.run_epoch(config, criterion, optimizer, is_train=True)\n",
    "                val_loss, val_distance = self.run_epoch(config, criterion, optimizer, is_train=False)\n",
    "                \n",
    "                # Early stopping and logging\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), f\"models/resnet18_best_model_checkpoint{model_name}.pth\")\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Stopping early after {patience} epochs without improvement\")\n",
    "                        break\n",
    "\n",
    "                # Log metrics to wandb\n",
    "                wandb.log({\n",
    "                    \"Train Loss\": train_loss,\n",
    "                    \"Train Distance\": train_distance,\n",
    "                    \"Validation Loss\": val_loss,\n",
    "                    \"Validation Distance\": val_distance\n",
    "                })\n",
    "\n",
    "    def run_epoch(self, config, criterion, optimizer, is_train=True):\n",
    "        if is_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_distance = 0.0\n",
    "        data_loader = train_dataloader if is_train else val_dataloader\n",
    "        \n",
    "        for images, coordinates, country_indices in data_loader:\n",
    "            with torch.set_grad_enabled(is_train):\n",
    "                images = images.to(self.device)\n",
    "                coordinates = coordinates.to(self.device) if self.use_coordinates else country_indices.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, coordinates)\n",
    "                \n",
    "                if is_train:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * images.size(0)\n",
    "                total_distance += mean_spherical_distance(outputs, coordinates).item() * images.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(data_loader.dataset)\n",
    "        avg_distance = total_distance / len(data_loader.dataset)\n",
    "        return avg_loss, avg_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\"]\n",
    "\n",
    "for model_type in model_types:\n",
    "    wandb.login()\n",
    "\n",
    "    sweep_config = {\n",
    "        \"name\": f\"dspro2-basemodel-{model_type}\",\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": \"minimize\", \"name\": \"Validation Distance\"},\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\"values\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]},\n",
    "            \"optimizer\": {\"values\": [\"adamW\"]},\n",
    "            \"weight_decay\": {\"values\": [1e-3]}, #1e-2, \n",
    "            \"epochs\": {\"values\": [500]},\n",
    "            \"dataset_size\": {\"values\": [NUMBER_OF_FILES]},\n",
    "            \"seed\": {\"values\": [42]},\n",
    "            \"model_name\": {\"values\": [model_type]}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=f\"dspro2-basemodel\")\n",
    "    trainer = GeoModelTrainer(model_type=model_type, num_classes=2, use_coordinates=True)\n",
    "    wandb.agent(sweep_id, function=trainer.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

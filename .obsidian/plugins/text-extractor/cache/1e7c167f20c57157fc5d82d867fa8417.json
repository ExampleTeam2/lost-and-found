{"path":"deliverables/240310_Proposal & Commitment/Proposal_group_ExampleTeam.pdf","text":"P r opos al for D S P R O 2 (F S 24) - L os t & F ou nd : P r e d icting L ocations fr om Im ag e s G r ou p M e m b e r s Linus Schlumberger Lukas St√∂ckli Y utaro Sigrist S h or t P r oje c t D e s c r iption As group we never have worked a lot with Image Classification nor worked with it. So, we want to create an Image Classification Model, which is based on simple street view images and predicts by looking at the images the country which the image represents as first step. As a second step, the model will be more advanced and the Model predicts the coordinate of the image instead of predicting the right country . Instead of addressing just one business case, the goal of this Image Classification model is to serve as a foundational model for multiple scenarios. But for what main purposes could an image classifier for countries or coordinates be valuable? D a ta D e s c r iption Our dataset consists of images obtained from Street V iew on Google Maps. Due to the high cost of Google Maps API, we utilized an alternative approach by using the game Geoguessr , which also uses Google Street V iew API. This game involves guessing the country or coordinates of a given location. The game of fers a cost-ef fective solution at only $5/Month for unlimited access. W e developed a script to automatically play the game, capture the country and coordinate data, and take a screenshot of the Street V iew image. This data, complete with coordinates and country information, will serve as the basis dataset for our classifier . Helping find missing persons: It can help find where missing people might be by analyzing pictures shared publicly . The emotional impact of helping reunite families or providing important clues is huge. Especially when the model will be used additionally to the finding process for a police. For missing people, every second counts after a kidnapping, especially when the person is missing internationally . Supporting Humanitarian Action: In disaster situations, it could help to quickly identify the most af fected areas by analyzing current images from social media or aid organizations. This would improve the coordination of rescue and relief ef forts and of fer hope and support to those af fected. Discover New Travel Destinations: Have you ever come across stunning images of places on Instagram or other social media platforms and wondered where they were taken? Our image classifier can help you with that. By analyzing the image, our classifier can identify the location and provide you with the information you need to plan your next visit to this amazing place. This way , you can discover new and exciting travel destinations that you may have never known about before. Classification as a Service: With this service, we will help other companies or data science projects to label their data. Sometimes companies want to block, permit or deploy individual versions of their applications in dif ferent countries. Some countries have more restrictions for deploying applications, therefore the image predictor can help the companies to have the right version on the right devices for these countries. C lou d S e r v ic e Inte g r a tion At the moment, we are utilizing a cloud service for data collection and preprocessing. W e have rented a server from Hetzner for web scraping. Currently , we are scraping images from Geoguessr and have accumulated a total of 60,000 images along with their locations in just one week. As part of the preprocessing task, we plan to reduce the size of the images on the server before processing them locally on our laptops. The server costs $5 per month, excluding bandwidth. For bandwidth, we only need to pay after using 20TB of data. Our goal is to avoid reaching this amount of data. The 60,000 images we have now amount to 90GB of data. Our plan for training the model and performing hyperparameter tuning involves using a cloud service due to the large size of the entire dataset. It would be impractical to train the model locally on a laptop. W e aim to conduct the more costly trainings on the GPU-Hub at HSLU to save costs. However , we are still undecided about which cloud service to choose. W e plan to carry out a thorough comparison of cost and performance before making a decision. All Data Quality Analysis (DQA) tasks will be carried out locally on our personal computers. K a nb a n Tool For our team, it is essential to use a Kanban tool that seamlessly integrates into our workflow and GitLab project. Our goal is to incorporate every document related to this project and store it within the GitLab repository . To achieve this, we utilize a Markdown file, which we enhance with plugins in the Obsidian application. The main benefit of this method is that we can operate with Markdown files in Obsidian and integrate them flawlessly into our GitLab workflow for synchronized files, version control, utilizing pull and push commands. Within these files, we organize tasks into five columns: Backlog, Current, Doing, Done, and Archive . The Backlog column contains all pending tasks, Current represents tasks for the immediate future, Doing includes tasks currently in progress, Done represents completed tasks (used for bug control and verification), and Archive is where tasks are stored after thorough review . Additionally , we can color-code tasks using hashtags, allowing us to structure our data science project workflow around key milestones that shape the project. E x pe r im e nt T r a c k ing Tool A ppr oa c h To keep track of our experiments and ensure reproducibility , we plan to use an experiment tracking tool. Specifically , we will use wandb.ai, a popular tool that allows for easy logging, visualization, and comparison of machine learning experiments. With wandb.ai, we can track our model's performance, hyperparameters, and other relevant metrics. W e will also store them seamlessly on our GitLab project to have a version control and the statistics locally on our laptops. This will enable us to compare dif ferent experiments and make informed decisions about which approaches to pursue further . By using wandb.ai, we can ensure that our experiments are well-documented and reproducible, which is essential for both research and development purposes.","libVersion":"0.3.1","langs":""}